{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install fast_ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression,LinearRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics, svm\n",
    "from fast_ml.model_development import train_valid_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score, mean_absolute_error\n",
    "\n",
    "def recallModel(Y_predicted, Y_true, datasetType: str, model):\n",
    "    if datasetType == \"Categorical\":\n",
    "        return metrics.recall_score(Y_predicted, Y_true, average = 'macro')\n",
    "    return metrics.r2_score(Y_true, Y_predicted)\n",
    "    \n",
    "\n",
    "def runModel(model, X_test, Y_test, datasetType: str): \n",
    "    Y_predicted = model.predict(X_test)\n",
    "    return recallModel (Y_predicted, Y_test,datasetType, model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models\n",
    "def trainCategoricalModel (X,Y):\n",
    "    return LogisticRegression().fit(X, Y)\n",
    "\n",
    "def trainCatergoricalModel_ (X,Y):\n",
    "    return GaussianNB().fit(X, Y)\n",
    "\n",
    "def trainCatModel (X,Y):\n",
    "    model  = svm.SVC(kernel='linear')\n",
    "    return model.fit(X, Y)\n",
    "\n",
    "def trainContinuousModel (X,Y):\n",
    "    return LinearRegression().fit(X, Y)\n",
    "\n",
    "def trainContinuousModel_ (X,Y):\n",
    "    Y = Y.astype('int')\n",
    "    model = KNeighborsClassifier(n_neighbors=1)\n",
    "    return model.fit(X,Y)\n",
    "\n",
    "def trainConModel(X,Y):\n",
    "    Y = Y.astype('int')\n",
    "    model = RandomForestRegressor(n_estimators= 1000, random_state=42)\n",
    "    return model.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def runModel(model, X_test, Y_test, datasetType: str): \n",
    "#     Y_predicted = model.predict(X_test)\n",
    "#     return recallModel (Y_predicted, Y_test,datasetType, model)\n",
    "\n",
    "\n",
    "# def runModel(model, X_test, Y_test,datasetType: str): \n",
    "#     Y_predicted = model.predict(X_test)\n",
    "#     return calculateAccuracy (Y_predicted, Y_test,datasetType, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def displayInfo (training, edge1, edge2, edge3, edge4):\n",
    "    print (\"Recall on Training Data: \", training)\n",
    "    print (\"Recall on edge1 Data: \", edge1)\n",
    "    print (\"Recall on edge2 Data: \", edge2)\n",
    "    print (\"Recall on edge3 Data: \", edge3)\n",
    "    print (\"Recall on edge4 Data: \", edge4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData (df,predictName: str,datasetType: str):\n",
    "\n",
    "    X = df.drop(columns=[predictName])  # Features\n",
    "    y = df[predictName]                # Target\n",
    "    \n",
    "    # First split: Split data into two halves (50% training and 50% for further splits)\n",
    "    model_train_X, X_remaining, model_train_Y, y_remaining = train_test_split(X, y, train_size=0.4, random_state=42)\n",
    "    \n",
    "    # Second split: Split the remaining data into 2 (50% for edge server 1 and 50% for edge server 2)\n",
    "    edgeServer1_X, edgeServer2_X, edgeServer1_Y, edgeServer2_Y = train_test_split(X_remaining, y_remaining, train_size=0.5, random_state=42)\n",
    "    \n",
    "    # Third split: Split the remaining data into 2 (50% for edge server 3 and 50% for edge server 4)\n",
    "    edgeServer3_X, edgeServer4_X, edgeServer3_Y, edgeServer4_Y = train_test_split(X_remaining, y_remaining, train_size=0.4, random_state=42)\n",
    "    \n",
    "    if datasetType == \"Categorical\":\n",
    "        model = trainCategoricalModel (model_train_X, model_train_Y)\n",
    "        \n",
    "    else:\n",
    "        model = trainContinuousModel (model_train_X, model_train_Y)\n",
    "        \n",
    "        \n",
    "    trainingAccuacy, edgeServer1Accuracy, edgeServer2Accuracy, edgeServer3Accuracy, edgeServer4Accuracy = runModel (model, model_train_X, model_train_Y,datasetType), runModel(model,edgeServer1_X, edgeServer1_Y,datasetType), runModel(model,edgeServer2_X, edgeServer2_Y,datasetType), runModel(model,edgeServer3_X, edgeServer3_Y,datasetType), runModel(model,edgeServer4_X, edgeServer4_Y,datasetType)\n",
    "\n",
    "    return trainingAccuacy, edgeServer1Accuracy, edgeServer2Accuracy, edgeServer3Accuracy, edgeServer4Accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loaddata (df,predictName: str,datasetType: str):\n",
    "    \n",
    "    X = df.drop(columns=[predictName])  # Features\n",
    "    y = df[predictName]                # Target\n",
    "    \n",
    "    # First split: Split data into two halves (50% training and 50% for further splits)\n",
    "    model_train_X, X_remaining, model_train_Y, y_remaining = train_test_split(X, y, train_size=0.4, random_state=42)\n",
    "    \n",
    "    # Second split: Split the remaining data into 2 (50% for edge server 1 and 50% for edge server 2)\n",
    "    edgeServer1_X, edgeServer2_X, edgeServer1_Y, edgeServer2_Y = train_test_split(X_remaining, y_remaining, train_size=0.5, random_state=42)\n",
    "    \n",
    "    # Third split: Split the remaining data into 2 (50% for edge server 3 and 50% for edge server 4)\n",
    "    edgeServer3_X, edgeServer4_X, edgeServer3_Y, edgeServer4_Y = train_test_split(X_remaining, y_remaining, train_size=0.5, random_state=42)\n",
    "    \n",
    "    if datasetType == \"Categorical\":\n",
    "        \n",
    "        model_a = trainCatergoricalModel_(model_train_X, model_train_Y)\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        model_a = trainContinuousModel_(model_train_X, model_train_Y)   \n",
    "    \n",
    "\n",
    "    training_A, edgeServer1_A, edgeServer2_A, edgeServer3_A, edgeServer4_A = runModel (model_a, model_train_X, model_train_Y,datasetType), runModel(model_a,edgeServer1_X, edgeServer1_Y,datasetType), runModel(model_a,edgeServer2_X, edgeServer2_Y,datasetType), runModel(model_a,edgeServer3_X, edgeServer3_Y,datasetType), runModel(model_a,edgeServer4_X, edgeServer4_Y,datasetType)\n",
    "    \n",
    "    return training_A, edgeServer1_A, edgeServer2_A, edgeServer3_A, edgeServer4_A\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data (df,predictName: str,datasetType: str):\n",
    "    \n",
    "    X = df.drop(columns=[predictName])  # Features\n",
    "    y = df[predictName]                # Target\n",
    "    \n",
    "    # First split: Split data into two halves (50% training and 50% for further splits)\n",
    "    model_train_X, X_remaining, model_train_Y, y_remaining = train_test_split(X, y, train_size=0.4, random_state=42)\n",
    "    \n",
    "    # Second split: Split the remaining data into 2 (50% for edge server 1 and 50% for edge server 2)\n",
    "    edgeServer1_X, edgeServer2_X, edgeServer1_Y, edgeServer2_Y = train_test_split(X_remaining, y_remaining, train_size=0.5, random_state=42)\n",
    "    \n",
    "    # Third split: Split the remaining data into 2 (50% for edge server 3 and 50% for edge server 4)\n",
    "    edgeServer3_X, edgeServer4_X, edgeServer3_Y, edgeServer4_Y = train_test_split(X_remaining, y_remaining, train_size=0.5, random_state=42)\n",
    "\n",
    "    \n",
    "    if datasetType == \"Categorical\":\n",
    "        \n",
    "        model_b = trainCatModel(model_train_X, model_train_Y)\n",
    "        \n",
    "    else:\n",
    "       \n",
    "        model_b = trainConModel(model_train_X, model_train_Y)\n",
    "        \n",
    "    training_B, edgeServer1_B, edgeServer2_B, edgeServer3_B, edgeServer4_B = runModel (model_b, model_train_X, model_train_Y,datasetType), runModel(model_b,edgeServer1_X, edgeServer1_Y,datasetType), runModel(model_b,edgeServer2_X, edgeServer2_Y,datasetType), runModel(model_b,edgeServer3_X, edgeServer3_Y,datasetType), runModel(model_b,edgeServer4_X, edgeServer4_Y,datasetType) \n",
    "    \n",
    "        \n",
    "    return training_B, edgeServer1_B, edgeServer2_B, edgeServer3_B, edgeServer4_B\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Occupancy():\n",
    "    print(\"-------------- Occupancy Dataset Info -------------------- \")\n",
    "    df = pd.read_csv('C:/Users/moyin/Downloads/data/Occupancy.csv')\n",
    "    df.drop(columns = [\"date\"],inplace = True)\n",
    "    trainingAccuacy, edgeServer1Accuracy, edgeServer2Accuracy, edgeServer3Accuracy, edgeServer4Accuracy = loadData(df,'Occupancy',\"Categorical\")\n",
    "    training_A, edgeServer1_A, edgeServer2_A, edgeServer3_A, edgeServer4_A = loaddata (df,'Occupancy',\"Categorical\")\n",
    "    training_B, edgeServer1_B, edgeServer2_B, edgeServer3_B, edgeServer4_B = load_data (df,'Occupancy',\"Categorical\")\n",
    "    displayInfo(trainingAccuacy, edgeServer1Accuracy, edgeServer2Accuracy, edgeServer3Accuracy, edgeServer4Accuracy)\n",
    "    print(\"------------------------------------------------------------\")\n",
    "    displayInfo(training_A, edgeServer1_A, edgeServer2_A, edgeServer3_A, edgeServer4_A)\n",
    "    print(\"------------------------------------------------------------\")\n",
    "    displayInfo(training_B, edgeServer1_B, edgeServer2_B, edgeServer3_B, edgeServer4_B)\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def powerConsumption():\n",
    "    print(\"-------------- Power Consumption Dataset Info -------------------- \")\n",
    "    df = pd.read_csv('C:/Users/moyin/Downloads/data/Tetuan City power consumption.csv')\n",
    "    df.drop(columns = ['DateTime','Zone 2  Power Consumption', 'Zone 3  Power Consumption'],inplace = True)\n",
    "    trainingAccuacy, edgeServer1Accuracy, edgeServer2Accuracy, edgeServer3Accuracy, edgeServer4Accuracy = loadData(df,'Zone 1 Power Consumption',\"Continuous\")\n",
    "    training_A, edgeServer1_A, edgeServer2_A, edgeServer3_A, edgeServer4_A = loaddata (df,'Zone 1 Power Consumption',\"Continuous\")\n",
    "    training_B, edgeServer1_B, edgeServer2_B, edgeServer3_B, edgeServer4_B = load_data (df,'Zone 1 Power Consumption',\"Continuous\")\n",
    "    displayInfo(trainingAccuacy, edgeServer1Accuracy, edgeServer2Accuracy, edgeServer3Accuracy, edgeServer4Accuracy)\n",
    "    print(\"------------------------------------------------------------\")\n",
    "    displayInfo(training_A, edgeServer1_A, edgeServer2_A, edgeServer3_A, edgeServer4_A)\n",
    "    print(\"------------------------------------------------------------\")\n",
    "    displayInfo(training_B, edgeServer1_B, edgeServer2_B, edgeServer3_B, edgeServer4_B)\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accelerometer_w():\n",
    "    print(\"-------------- Accelerometer Dataset Info -------------------- \")\n",
    "    df = pd.read_csv('C:/Users/moyin/Downloads/data/accelerometer.csv')\n",
    "#     df.drop(columns = ['wconfid','pctid', 'x', 'y', 'z'],inplace = True)\n",
    "    trainingAccuacy, edgeServer1Accuracy, edgeServer2Accuracy, edgeServer3Accuracy, edgeServer4Accuracy = loadData(df,'wconfid',\"Continuous\")\n",
    "    training_A, edgeServer1_A, edgeServer2_A, edgeServer3_A, edgeServer4_A = loaddata (df,'wconfid',\"Continuous\")\n",
    "    training_B, edgeServer1_B, edgeServer2_B, edgeServer3_B, edgeServer4_B = load_data (df,'wconfid',\"Continuous\")\n",
    "    displayInfo(trainingAccuacy, edgeServer1Accuracy, edgeServer2Accuracy, edgeServer3Accuracy, edgeServer4Accuracy)\n",
    "    print(\"------------------------------------------------------------\")\n",
    "    displayInfo(training_A, edgeServer1_A, edgeServer2_A, edgeServer3_A, edgeServer4_A)\n",
    "    print(\"------------------------------------------------------------\")\n",
    "    displayInfo(training_B, edgeServer1_B, edgeServer2_B, edgeServer3_B, edgeServer4_B)\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activity_wsdata():\n",
    "    print(\"-------------- Wearable Sensor Dataset Info -------------------- \")\n",
    "    df = pd.read_csv('C:/Users/moyin/Downloads/data/activity data.csv')\n",
    "    trainingAccuacy, edgeServer1Accuracy, edgeServer2Accuracy, edgeServer3Accuracy, edgeServer4Accuracy = loadData(df,'activity',\"Categorical\")\n",
    "    training_A, edgeServer1_A, edgeServer2_A, edgeServer3_A, edgeServer4_A = loaddata (df,'activity',\"Categorical\")\n",
    "    training_B, edgeServer1_B, edgeServer2_B, edgeServer3_B, edgeServer4_B = load_data (df,'activity',\"Categorical\")\n",
    "    displayInfo(trainingAccuacy, edgeServer1Accuracy, edgeServer2Accuracy, edgeServer3Accuracy, edgeServer4Accuracy)\n",
    "    print(\"------------------------------------------------------------\")\n",
    "    displayInfo(training_A, edgeServer1_A, edgeServer2_A, edgeServer3_A, edgeServer4_A)\n",
    "    print(\"------------------------------------------------------------\")\n",
    "    displayInfo(training_B, edgeServer1_B, edgeServer2_B, edgeServer3_B, edgeServer4_B)\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ALEdata():\n",
    "    print(\"-------------- ALE Sensor Data Dataset Info -------------------- \")\n",
    "    df = pd.read_csv('C:/Users/moyin/Downloads/data/ALE in Sensor.csv')\n",
    "    trainingAccuacy, edgeServer1Accuracy, edgeServer2Accuracy, edgeServer3Accuracy, edgeServer4Accuracy = loadData(df,'sd_ale',\"Continuous\")\n",
    "    training_A, edgeServer1_A, edgeServer2_A, edgeServer3_A, edgeServer4_A  = loaddata (df,'sd_ale',\"Continuous\")\n",
    "    training_B, edgeServer1_B, edgeServer2_B, edgeServer3_B, edgeServer4_B = load_data (df,'sd_ale',\"Continuous\")\n",
    "    displayInfo(trainingAccuacy, edgeServer1Accuracy, edgeServer2Accuracy, edgeServer3Accuracy, edgeServer4Accuracy)\n",
    "    print(\"------------------------------------------------------------\")\n",
    "    displayInfo(training_A, edgeServer1_A, edgeServer2_A, edgeServer3_A, edgeServer4_A)\n",
    "    print(\"------------------------------------------------------------\")\n",
    "    displayInfo(training_B, edgeServer1_B, edgeServer2_B, edgeServer3_B, edgeServer4_B)\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def banknote_data():\n",
    "    print(\"-------------- Bank Note Authentication Dataset Info -------------------- \")\n",
    "    df = pd.read_csv('C:/Users/moyin/Downloads/data/banknote_authen.txt')\n",
    "    trainingAccuacy, edgeServer1Accuracy, edgeServer2Accuracy, edgeServer3Accuracy, edgeServer4Accuracy = loadData(df,'class',\"Categorical\")\n",
    "    training_A, edgeServer1_A, edgeServer2_A, edgeServer3_A, edgeServer4_A = loaddata (df,'class',\"Categorical\")\n",
    "    training_B, edgeServer1_B, edgeServer2_B, edgeServer3_B, edgeServer4_B = load_data (df,'class',\"Categorical\")\n",
    "    displayInfo(trainingAccuacy, edgeServer1Accuracy, edgeServer2Accuracy, edgeServer3Accuracy, edgeServer4Accuracy)\n",
    "    print(\"------------------------------------------------------------\")\n",
    "    displayInfo(training_A, edgeServer1_A, edgeServer2_A, edgeServer3_A, edgeServer4_A)\n",
    "    print(\"------------------------------------------------------------\")\n",
    "    displayInfo(training_B, edgeServer1_B, edgeServer2_B, edgeServer3_B, edgeServer4_B)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RSSI():\n",
    "    print(\"-------------- BLE RSSI Dataset Info -------------------- \")\n",
    "    df = pd.read_csv('C:/Users/moyin/Downloads/data/BLE RSSI.csv')\n",
    "    df.drop(columns = ['name'],inplace = True)\n",
    "    trainingAccuacy, edgeServer1Accuracy, edgeServer2Accuracy, edgeServer3Accuracy, edgeServer4Accuracy = loadData(df,'locationStatus', \"Categorical\")\n",
    "    training_A, edgeServer1_A, edgeServer2_A, edgeServer3_A, edgeServer4_A  = loaddata (df,'locationStatus', \"Categorical\")\n",
    "    training_B, edgeServer1_B, edgeServer2_B, edgeServer3_B, edgeServer4_B  = load_data (df,'locationStatus', \"Categorical\")\n",
    "    displayInfo(trainingAccuacy, edgeServer1Accuracy, edgeServer2Accuracy, edgeServer3Accuracy, edgeServer4Accuracy)\n",
    "    print(\"------------------------------------------------------------\")\n",
    "    displayInfo(training_A, edgeServer1_A, edgeServer2_A, edgeServer3_A, edgeServer4_A)\n",
    "    print(\"------------------------------------------------------------\")\n",
    "    displayInfo(training_B, edgeServer1_B, edgeServer2_B, edgeServer3_B, edgeServer4_B)\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def e_grid():\n",
    "    print(\"-------------- Simulated Electrical Grid Dataset Info -------------------- \")\n",
    "    df = pd.read_csv('C:/Users/moyin/Downloads/data/UCI_named.csv')\n",
    "    trainingAccuacy, edgeServer1Accuracy, edgeServer2Accuracy, edgeServer3Accuracy, edgeServer4Accuracy = loadData(df,'stabf', 'Categorical')\n",
    "    training_A, edgeServer1_A, edgeServer2_A, edgeServer3_A, edgeServer4_A  = loaddata (df,'stabf', 'Categorical')\n",
    "    training_B, edgeServer1_B, edgeServer2_B, edgeServer3_B, edgeServer4_B = load_data (df,'stabf', 'Categorical')\n",
    "    displayInfo(trainingAccuacy, edgeServer1Accuracy, edgeServer2Accuracy, edgeServer3Accuracy, edgeServer4Accuracy)\n",
    "    print(\"------------------------------------------------------------\")\n",
    "    displayInfo(training_A, edgeServer1_A, edgeServer2_A, edgeServer3_A, edgeServer4_A)\n",
    "    print(\"------------------------------------------------------------\")\n",
    "    displayInfo(training_B, edgeServer1_B, edgeServer2_B, edgeServer3_B, edgeServer4_B)\n",
    "    return  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__==\"__main__\":\n",
    "#     Occupancy()\n",
    "#     powerConsumption()\n",
    "#     accelerometer_w()\n",
    "#     activity_wsdata()\n",
    "#     ALEdata()\n",
    "#     banknote_data()\n",
    "#     RSSI()\n",
    "#     e_grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------- Occupancy Dataset Info -------------------- \n",
      "Recall on Training Data:  0.9742626894340249\n",
      "Recall on edge1 Data:  0.9826525851588015\n",
      "Recall on edge2 Data:  0.9805667539905484\n",
      "Recall on edge3 Data:  0.9849098297443198\n",
      "Recall on edge4 Data:  0.9793891496366611\n",
      "------------------------------------------------------------\n",
      "Recall on Training Data:  0.9364947338137272\n",
      "Recall on edge1 Data:  0.9427749166425125\n",
      "Recall on edge2 Data:  0.9372447082037307\n",
      "Recall on edge3 Data:  0.9427749166425125\n",
      "Recall on edge4 Data:  0.9372447082037307\n",
      "------------------------------------------------------------\n",
      "Recall on Training Data:  0.9741139562930157\n",
      "Recall on edge1 Data:  0.9827699386392282\n",
      "Recall on edge2 Data:  0.9800412620750669\n",
      "Recall on edge3 Data:  0.9827699386392282\n",
      "Recall on edge4 Data:  0.9800412620750669\n"
     ]
    }
   ],
   "source": [
    "Occupancy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------- Power Consumption Dataset Info -------------------- \n",
      "Recall on Training Data:  0.2027594046484852\n",
      "Recall on edge1 Data:  0.20574927510387442\n",
      "Recall on edge2 Data:  0.21342267738051168\n",
      "Recall on edge3 Data:  0.2039750439211221\n",
      "Recall on edge4 Data:  0.21330338109370983\n",
      "------------------------------------------------------------\n",
      "Recall on Training Data:  0.999999993588981\n",
      "Recall on edge1 Data:  -0.05201312579924089\n",
      "Recall on edge2 Data:  -0.0484122752946603\n",
      "Recall on edge3 Data:  -0.05201312579924089\n",
      "Recall on edge4 Data:  -0.0484122752946603\n",
      "------------------------------------------------------------\n",
      "Recall on Training Data:  0.9344843684236297\n",
      "Recall on edge1 Data:  0.5064163270474468\n",
      "Recall on edge2 Data:  0.5152111463112402\n",
      "Recall on edge3 Data:  0.5064163270474468\n",
      "Recall on edge4 Data:  0.5152111463112402\n"
     ]
    }
   ],
   "source": [
    "powerConsumption()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------- Accelerometer Dataset Info -------------------- \n",
      "Recall on Training Data:  7.65210790154569e-05\n",
      "Recall on edge1 Data:  5.6376002772418055e-05\n",
      "Recall on edge2 Data:  -0.00014952806744905622\n",
      "Recall on edge3 Data:  3.07991945365238e-05\n",
      "Recall on edge4 Data:  -1.889229437024298e-05\n",
      "------------------------------------------------------------\n",
      "Recall on Training Data:  0.9531800745860894\n",
      "Recall on edge1 Data:  0.25144335092716896\n",
      "Recall on edge2 Data:  0.2501146278536095\n",
      "Recall on edge3 Data:  0.25144335092716896\n",
      "Recall on edge4 Data:  0.2501146278536095\n",
      "------------------------------------------------------------\n",
      "Recall on Training Data:  0.922768543738738\n",
      "Recall on edge1 Data:  0.5500364104947754\n",
      "Recall on edge2 Data:  0.5550193240880725\n",
      "Recall on edge3 Data:  0.5500364104947754\n",
      "Recall on edge4 Data:  0.5550193240880725\n"
     ]
    }
   ],
   "source": [
    "accelerometer_w()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------- Wearable Sensor Dataset Info -------------------- \n",
      "Recall on Training Data:  0.997983870967742\n",
      "Recall on edge1 Data:  0.6639784946236559\n",
      "Recall on edge2 Data:  0.32798573975044565\n",
      "Recall on edge3 Data:  0.6632996632996634\n",
      "Recall on edge4 Data:  0.32887899034892354\n",
      "------------------------------------------------------------\n",
      "Recall on Training Data:  1.0\n",
      "Recall on edge1 Data:  0.6648697214734951\n",
      "Recall on edge2 Data:  0.3288650580875782\n",
      "Recall on edge3 Data:  0.6648697214734951\n",
      "Recall on edge4 Data:  0.3288650580875782\n",
      "------------------------------------------------------------\n",
      "Recall on Training Data:  1.0\n",
      "Recall on edge1 Data:  0.5\n",
      "Recall on edge2 Data:  0.4148648648648649\n",
      "Recall on edge3 Data:  0.5\n",
      "Recall on edge4 Data:  0.4148648648648649\n"
     ]
    }
   ],
   "source": [
    "activity_wsdata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------- ALE Sensor Data Dataset Info -------------------- \n",
      "Recall on Training Data:  0.684419755654035\n",
      "Recall on edge1 Data:  0.7009833823571244\n",
      "Recall on edge2 Data:  0.40898865597025014\n",
      "Recall on edge3 Data:  0.6914464514462756\n",
      "Recall on edge4 Data:  0.4833816592230403\n",
      "------------------------------------------------------------\n",
      "Recall on Training Data:  -2.204074310664261\n",
      "Recall on edge1 Data:  -1.6997869395144232\n",
      "Recall on edge2 Data:  -2.748503755022698\n",
      "Recall on edge3 Data:  -1.6997869395144232\n",
      "Recall on edge4 Data:  -2.748503755022698\n",
      "------------------------------------------------------------\n",
      "Recall on Training Data:  -2.204074310664261\n",
      "Recall on edge1 Data:  -1.6997869395144232\n",
      "Recall on edge2 Data:  -2.748503755022698\n",
      "Recall on edge3 Data:  -1.6997869395144232\n",
      "Recall on edge4 Data:  -2.748503755022698\n"
     ]
    }
   ],
   "source": [
    "ALEdata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------- Bank Note Authentication Dataset Info -------------------- \n",
      "Recall on Training Data:  0.9904751712328768\n",
      "Recall on edge1 Data:  0.9917127071823204\n",
      "Recall on edge2 Data:  0.9873563218390804\n",
      "Recall on edge3 Data:  0.9964788732394366\n",
      "Recall on edge4 Data:  0.9849612864800477\n",
      "------------------------------------------------------------\n",
      "Recall on Training Data:  0.8491612554112553\n",
      "Recall on edge1 Data:  0.8531426318772021\n",
      "Recall on edge2 Data:  0.8104172703564184\n",
      "Recall on edge3 Data:  0.8531426318772021\n",
      "Recall on edge4 Data:  0.8104172703564184\n",
      "------------------------------------------------------------\n",
      "Recall on Training Data:  0.9922178988326849\n",
      "Recall on edge1 Data:  0.9917127071823204\n",
      "Recall on edge2 Data:  0.9873563218390804\n",
      "Recall on edge3 Data:  0.9917127071823204\n",
      "Recall on edge4 Data:  0.9873563218390804\n"
     ]
    }
   ],
   "source": [
    "banknote_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------- BLE RSSI Dataset Info -------------------- \n"
     ]
    }
   ],
   "source": [
    "RSSI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
