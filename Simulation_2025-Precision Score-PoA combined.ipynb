{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install fast_ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression,LinearRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics, svm\n",
    "from fast_ml.model_development import train_valid_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "# datasets\n",
    "powerConsumption = pd.read_csv('C:/Users/moyin/Downloads/data/Tetuan City power consumption.csv')\n",
    "activity_wsdata = pd.read_csv('C:/Users/moyin/Downloads/data/activity data.csv')\n",
    "ALEdata = pd.read_csv('C:/Users/moyin/Downloads/data/ALE in Sensor.csv')\n",
    "Occupancy = pd.read_csv('C:/Users/moyin/Downloads/data/Occupancy.csv')\n",
    "poisioned_data = pd.read_csv('C:/Users/moyin/Downloads/data/bad_dataset.csv')\n",
    "\n",
    "# poisoned data \n",
    "target = 'Occupancy'\n",
    "X_p = poisioned_data.drop(columns=[target])\n",
    "y_p = poisioned_data[target]\n",
    "\n",
    "# split data\n",
    "X_train_p, X_test_p, y_train_p, y_test_p = train_test_split(X_p, y_p, test_size=0.5, random_state=42)\n",
    "model_train_p, model_test_p, target_train_p, target_test_p = train_test_split(X_train_p, y_train_p, test_size=0.5, random_state=42)\n",
    "edgeDevice_X_p, edgeData_X_p, edgeDevice_Y_p, edgeData_Y_p = train_test_split(model_train_p, target_train_p, train_size=0.5, random_state=42)\n",
    "edgeServer1_X_p, edgeServer2_X_p, edgeServer1_Y_p, edgeServer2_Y_p = train_test_split(edgeDevice_X_p, edgeData_X_p, train_size=0.5, random_state=42)\n",
    "\n",
    "\n",
    "# clean data \n",
    "target = 'Occupancy'\n",
    "X = Occupancy.drop(columns=[target])\n",
    "y = Occupancy[target]\n",
    "\n",
    "# split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)\n",
    "model_train, model_test, target_train, target_test = train_test_split(X_train, y_train, test_size=0.5, random_state=42)\n",
    "edgeDevice_X, edgeData_X, edgeDevice_Y, edgeData_Y = train_test_split(model_train, target_train, train_size=0.5, random_state=42)\n",
    "edgeServer1_X, edgeServer2_X, edgeServer1_Y, edgeServer2_Y = train_test_split(edgeDevice_X, edgeData_X, train_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import time\n",
    "import random as rand\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# node representing each block\n",
    "class Node:\n",
    "    \n",
    "    def __init__(self, idx, prev_hash, t_stamp, transactions, proof, validator):\n",
    "        self.idx = idx\n",
    "        self.prev_hash = prev_hash\n",
    "        self.t_stamp = t_stamp\n",
    "        self.transactions = transactions\n",
    "        self.proof = proof\n",
    "        self.validator = validator\n",
    "        self.hash = self.calculate_hash()\n",
    "    \n",
    "    def calculate_hash(self):\n",
    "        node_str = f\"{self.idx}{self.prev_hash}{self.t_stamp}{self.transactions}{self.proof}{self.validator}\"\n",
    "        return hashlib.sha256(node_str.encode('utf-8')).hexdigest()\n",
    "        \n",
    "        \n",
    "class Blockchain_Network:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.chain = []\n",
    "        self.transactions = []\n",
    "        self.c_node_idx = 0         \n",
    "        self.validators = ['R_Edge_Server_A', 'R_Edge_Server_B', 'R_Edge_Server_C', 'R_Edge_Server_D']\n",
    "        self.add_node()\n",
    "        self.consensus_threshold = 2  \n",
    "    \n",
    "    def add_node(self):\n",
    "        # initial block\n",
    "        if self.c_node_idx == 0:\n",
    "            start_node = Node(0, \"0\", time.time(), [], 'Start', 'System')\n",
    "            self.chain.append(start_node)\n",
    "            self.c_node_idx += 1\n",
    "    \n",
    "    # simulate a transaction creation  data: model's data, accuracy: model's accuracy\n",
    "    def transaction_session(self, source, receiver, data, accuracy):\n",
    "        transaction = {\"AI Vendor\": source, \"Edge Device\": receiver, \"model data\": data, \"model accuracy\": accuracy}\n",
    "        self.transactions.append(transaction)\n",
    "        \n",
    "    # Simulate the mining process\n",
    "    def mine_node(self):\n",
    "        \n",
    "        validator = rand.choice(self.validators) \n",
    "        t_stamp = time.time()\n",
    "        \n",
    "        # Simulate proof of authority by generating a random proof\n",
    "        proof = rand.randint(150, 8500)  \n",
    "        node = Node(self.c_node_idx, self.chain[-1].hash, t_stamp, self.transactions, proof, validator)\n",
    "\n",
    "        # Check for data integrity and accuracy before adding the node\n",
    "        integrity_check = self.data_integrity(node.transactions)\n",
    "        accuracy_check = self.is_valid_model(node.transactions)\n",
    "\n",
    "        if not integrity_check or not accuracy_check:\n",
    "            if not integrity_check:\n",
    "                print(f\"Node {node.idx} failed the data integrity check. Node discarded and mining continues.\")\n",
    "            if not accuracy_check:\n",
    "                print(f\"Node {node.idx} failed the model accuracy check. Node discarded and mining continues.\")\n",
    "\n",
    "            self.c_node_idx += 1\n",
    "            continue\n",
    "        \n",
    "        \n",
    "\n",
    "        votes = self.node_votes(node)\n",
    "        # print(f\"Validator Votes: {votes}\")\n",
    "        \n",
    "        if integrity_check and accuracy_check:\n",
    "            # Simulate validator votes for the block\n",
    "            votes = self.node_votes(node)\n",
    "            \n",
    "            if len(votes) >= self.consensus_threshold: \n",
    "                self.chain.append(node)  \n",
    "                self.c_node_idx += 1\n",
    "                self.transactions = [] \n",
    "                \n",
    "                print(f\"Node {node.idx} successfully added to the blockchain.\")\n",
    "            else:          \n",
    "                print(f\"Node {node.idx} failed to reach consensus. Node discarded and mining continues.\")\n",
    "        return node\n",
    "            \n",
    "\n",
    "     # Simulate validators voting on the block   \n",
    "    def node_votes(self, node):\n",
    "        votes = []\n",
    "        \n",
    "        for validator in self.validators:\n",
    "            # if self.data_integrity(node.transactions) and self.is_valid_model(node.transactions):\n",
    "                votes.append(validator)   \n",
    "        return votes\n",
    "\n",
    "\n",
    "    def data_integrity(self, transactions):\n",
    "        # accuracy, consistency, data mismatch, and outliers \n",
    "        for transaction in transactions:\n",
    "            if isinstance(transaction['model data'], pd.DataFrame):\n",
    "                missing_values = transaction['model data'].isnull().sum().sum()\n",
    "                duplicate_values = transaction['model data'].duplicated().sum()\n",
    "                incorrect_data = 0\n",
    "                \n",
    "                for col in transaction['model data'].select_dtypes(include=[np.number]).columns:\n",
    "                    if not pd.api.types.is_numeric_dtype(transaction['model data'][col]):\n",
    "                        incorrect_data += 1\n",
    "                \n",
    "                if missing_values > 0 or duplicate_values > 0 or incorrect_data > 0:\n",
    "                    return False\n",
    "            else:\n",
    "                # Assuming model data is numeric\n",
    "                if not isinstance(transaction['model data'], (int, float)):\n",
    "                    return False\n",
    "\n",
    "        return True\n",
    "        \n",
    "        \n",
    "    def is_valid_model(self, transactions):\n",
    "        \n",
    "        expected_accuracy = 80 \n",
    "       \n",
    "        for transaction in transactions:\n",
    "            if 'model accuracy' in transaction:\n",
    "                m_accuracy = transaction['model accuracy']\n",
    "                if m_accuracy < expected_accuracy:\n",
    "                    return False             \n",
    "        return True  \n",
    "\n",
    "    \n",
    "    def get_last_node(self):\n",
    "        return self.chain[-1]\n",
    "\n",
    "    \n",
    "    def display_chain(self):\n",
    "        for node in self.chain:\n",
    "            print(f\"------ Session Begins --------\")\n",
    "            print(f\"Node {node.idx}: {node.hash} | Validator: {node.validator} | Proof: {node.proof}\")\n",
    "            # print(f\"Transactions: {node.transactions}\")\n",
    "            print(f\"----------------------------\")\n",
    "            print(f\"----------------------------\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the blockchain\n",
    "PoA_consensus = Blockchain_Network()\n",
    "\n",
    "# Simulate creating transactions\n",
    "    # source: AI Marketplace represented as App_VendorID\n",
    "    # receiver: edge devices defined as ED_RegionID_DeviceID where ED represents the edge device\n",
    "    # model data: the AI model parameters\n",
    "    # model accuracy: the accuracy given by the vendor\n",
    "\n",
    "# # Display the updated blockchain\n",
    "# PoA_consensus.display_chain()\n",
    "\n",
    "# transaction 1\n",
    "PoA_consensus.transaction_session(\"App_V01\", \"ED_R1_AR1\", model_train, 85)\n",
    "PoA_consensus.transaction_session(\"App_V01\", \"ED_R2_AR2\", edgeDevice_X, 80)\n",
    "# Mine another block\n",
    "PoA_consensus.mine_node()\n",
    "\n",
    "# # Display the updated blockchain\n",
    "# PoA_consensus.display_chain()\n",
    "\n",
    "# transaction 2\n",
    "PoA_consensus.transaction_session(\"App_V03\", \"ED_R4_AR1\", edgeDevice_X, 90)\n",
    "PoA_consensus.transaction_session(\"App_V04\", \"ED_R3_AR2\", X_train, 100)\n",
    "\n",
    "# Mine another block\n",
    "PoA_consensus.mine_node()\n",
    "\n",
    "# # Display the updated blockchain\n",
    "# PoA_consensus.display_chain()\n",
    "\n",
    "# transaction 3\n",
    "PoA_consensus.transaction_session(\"App_V02\", \"ED_R2_AR2\", edgeServer1_X, 82)\n",
    "PoA_consensus.transaction_session(\"App_V02\", \"ED_R2_AR2\", edgeDevice_X, 81)\n",
    "# Mine another block\n",
    "PoA_consensus.mine_node()\n",
    "\n",
    "# # Display the updated blockchain\n",
    "# PoA_consensus.display_chain()\n",
    "\n",
    "# transaction 4\n",
    "PoA_consensus.transaction_session(\"App_V04\", \"ED_R3_AR4\", edgeServer1_X, 95)\n",
    "PoA_consensus.transaction_session(\"App_V03\", \"ED_R3_AR2\", edgeServer1_X, 80)\n",
    "# Mine another block\n",
    "PoA_consensus.mine_node()\n",
    "\n",
    "# # Display the updated blockchain\n",
    "# PoA_consensus.display_chain()\n",
    "\n",
    "# transaction 5\n",
    "PoA_consensus.transaction_session(\"App_V02\", \"ED_R4_AR1\", model_train, 100)\n",
    "PoA_consensus.transaction_session(\"App_V01\", \"ED_R2_AR2\", edgeDevice_X, 100)\n",
    "# Mine another block\n",
    "PoA_consensus.mine_node()\n",
    "\n",
    "# # Display the updated blockchain\n",
    "# PoA_consensus.display_chain()\n",
    "\n",
    "# transaction 6\n",
    "PoA_consensus.transaction_session(\"App_V01\", \"ED_R2_AR4\", X_train, 95)\n",
    "PoA_consensus.transaction_session(\"App_V03\", \"ED_R2_AR2\", edgeDevice_X, 80)\n",
    "# Mine another block\n",
    "PoA_consensus.mine_node()\n",
    "\n",
    "# # Display the updated blockchain\n",
    "# PoA_consensus.display_chain()\n",
    "\n",
    "# transaction 7\n",
    "PoA_consensus.transaction_session(\"App_V02\", \"ED_R3_AR4\", model_train, 85)\n",
    "PoA_consensus.transaction_session(\"App_V01\", \"ED_R2_AR2\", edgeServer2_X, 80)\n",
    "# Mine another block\n",
    "PoA_consensus.mine_node()\n",
    "\n",
    "# # Display the updated blockchain\n",
    "# PoA_consensus.display_chain()\n",
    "\n",
    "# transaction 8\n",
    "PoA_consensus.transaction_session(\"App_V04\", \"ED_R2_AR4\", edgeServer2_X, 85)\n",
    "PoA_consensus.transaction_session(\"App_V03\", \"ED_R2_AR5\", edgeData_X_p, 80)\n",
    "# Mine another block\n",
    "PoA_consensus.mine_node()\n",
    "\n",
    "# # Display the updated blockchain\n",
    "# PoA_consensus.display_chain()\n",
    "\n",
    "# transaction 9\n",
    "PoA_consensus.transaction_session(\"App_V02\", \"ED_R4_AR1\", model_train, 85)\n",
    "PoA_consensus.transaction_session(\"App_V03\", \"ED_R4_AR2\", edgeDevice_X, 80)\n",
    "# Mine another block\n",
    "PoA_consensus.mine_node()\n",
    "\n",
    "# # Display the updated blockchain\n",
    "# PoA_consensus.display_chain()\n",
    "\n",
    "# transaction 10\n",
    "PoA_consensus.transaction_session(\"App_V03\", \"ED_R1_AR1\", model_train_p, 85)\n",
    "PoA_consensus.transaction_session(\"App_V02\", \"ED_R2_AR2\", edgeDevice_X_p, 80)\n",
    "# Mine another block\n",
    "PoA_consensus.mine_node()\n",
    "\n",
    "# # Display the updated blockchain\n",
    "# PoA_consensus.display_chain()\n",
    "\n",
    "# transaction 11\n",
    "PoA_consensus.transaction_session(\"App_V02\", \"ED_R4_AR1\", model_train, 85)\n",
    "PoA_consensus.transaction_session(\"App_V03\", \"ED_R4_AR2\", edgeDevice_X, 80)\n",
    "# Mine another block\n",
    "PoA_consensus.mine_node()\n",
    "\n",
    "# # Display the updated blockchain\n",
    "# PoA_consensus.display_chain()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# increase the number of edge servers to 10 -15 servers; randomly assign poision the data that is passed to it\n",
    "# if all the values is 100% for the TP and FP, no need for graph...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import time\n",
    "import random as rand\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Node representing each block\n",
    "class Node:\n",
    "    def __init__(self, idx, prev_hash, t_stamp, transactions, proof, validator):\n",
    "        self.idx = idx\n",
    "        self.prev_hash = prev_hash\n",
    "        self.t_stamp = t_stamp\n",
    "        self.transactions = transactions\n",
    "        self.proof = proof\n",
    "        self.validator = validator\n",
    "        self.hash = self.calculate_hash()\n",
    "    \n",
    "    def calculate_hash(self):\n",
    "        node_str = f\"{self.idx}{self.prev_hash}{self.t_stamp}{self.transactions}{self.proof}{self.validator}\"\n",
    "        return hashlib.sha256(node_str.encode('utf-8')).hexdigest()\n",
    "\n",
    "\n",
    "class Blockchain_Network:\n",
    "    def __init__(self):\n",
    "        self.chain = []\n",
    "        self.transactions = []\n",
    "        self.c_node_idx = 0         \n",
    "        self.validators = ['R_Edge_Server_A', 'R_Edge_Server_B', 'R_Edge_Server_C', 'R_Edge_Server_D']\n",
    "        self.add_node()\n",
    "        self.consensus_threshold = 2  \n",
    "    \n",
    "    def add_node(self):\n",
    "        # Initial block\n",
    "        if self.c_node_idx == 0:\n",
    "            start_node = Node(0, \"0\", time.time(), [], 'Start', 'System')\n",
    "            self.chain.append(start_node)\n",
    "            self.c_node_idx += 1\n",
    "    \n",
    "    # Simulate a transaction creation data: model's data, accuracy: model's accuracy\n",
    "    def transaction_session(self, source, receiver, data, accuracy):\n",
    "        transaction = {\"AI Vendor\": source, \"Edge Device\": receiver, \"model data\": data, \"model accuracy\": accuracy}\n",
    "        self.transactions.append(transaction)\n",
    "        \n",
    "    # Simulate the mining process\n",
    "    def mine_node(self):\n",
    "        while True:\n",
    "            validator = rand.choice(self.validators) \n",
    "            t_stamp = time.time()\n",
    "\n",
    "            # Simulate proof of authority by generating a random proof\n",
    "            proof = rand.randint(150, 8500)  \n",
    "            node = Node(self.c_node_idx, self.chain[-1].hash, t_stamp, self.transactions, proof, validator)\n",
    "\n",
    "            # Check for data integrity and accuracy before adding the node\n",
    "            integrity_check = self.data_integrity(node.transactions)\n",
    "            accuracy_check = self.is_valid_model(node.transactions)\n",
    "\n",
    "            # If node fails integrity or accuracy check, log the failure but continue mining\n",
    "            if not integrity_check or not accuracy_check:\n",
    "                if not integrity_check:\n",
    "                    print(f\"Node {node.idx} failed the data integrity check. Skipping this node.\")\n",
    "                if not accuracy_check:\n",
    "                    print(f\"Node {node.idx} failed the model accuracy check. Skipping this node.\")\n",
    "\n",
    "                # Increment the node index and continue to try mining the next node\n",
    "                self.c_node_idx += 1\n",
    "                continue  # Go back to the top of the while loop and try mining a new node\n",
    "            \n",
    "            # Simulate validator votes for the block\n",
    "            votes = self.node_votes(node)\n",
    "            if len(votes) >= self.consensus_threshold:\n",
    "                self.chain.append(node)  \n",
    "                self.transactions = [] \n",
    "                print(f\"Node {node.idx} successfully added to the blockchain.\")\n",
    "                break  # Exit the loop when the node is valid and added to the chain\n",
    "            else:          \n",
    "                print(f\"Node {node.idx} failed to reach consensus. Skipping this node and continuing mining.\")  \n",
    "                self.c_node_idx += 1  # Increment the index after a failed consensus\n",
    "                continue  # Continue mining the next node\n",
    "\n",
    "    # Simulate validators voting on the block   \n",
    "    def node_votes(self, node):\n",
    "        votes = []\n",
    "        \n",
    "        for validator in self.validators:\n",
    "            # Only cast a vote if both integrity and accuracy checks pass\n",
    "            if self.data_integrity(node.transactions) and self.is_valid_model(node.transactions):\n",
    "                votes.append(validator)   \n",
    "        return votes\n",
    "\n",
    "\n",
    "    def data_integrity(self, transactions):\n",
    "        # Debugging print to see the transactions\n",
    "        # print(\"Checking data integrity...\")\n",
    "        for transaction in transactions:\n",
    "            # print(f\"Transaction Data: {transaction}\")\n",
    "            \n",
    "            if isinstance(transaction['model data'], pd.DataFrame):\n",
    "                missing_values = transaction['model data'].isnull().sum().sum()\n",
    "                duplicate_values = transaction['model data'].duplicated().sum()\n",
    "                incorrect_data = 0\n",
    "                \n",
    "                for col in transaction['model data'].select_dtypes(include=[np.number]).columns:\n",
    "                    if not pd.api.types.is_numeric_dtype(transaction['model data'][col]):\n",
    "                        incorrect_data += 1\n",
    "                \n",
    "                if missing_values > 0 or duplicate_values > 0 or incorrect_data > 0:\n",
    "                    # print(f\"Integrity issue found: Missing {missing_values}, Duplicates {duplicate_values}, Incorrect Data {incorrect_data}\")\n",
    "                    return False\n",
    "            else:\n",
    "                # Assuming model data is numeric\n",
    "                if not isinstance(transaction['model data'], (int, float)):\n",
    "                    print(f\"Integrity issue found: Invalid data type {type(transaction['model data'])}\")\n",
    "                    return False\n",
    "        \n",
    "        return True\n",
    "        \n",
    "        \n",
    "    def is_valid_model(self, transactions):\n",
    "        expected_accuracy = 80  # Minimum acceptable accuracy\n",
    "       \n",
    "        for transaction in transactions:\n",
    "            if 'model accuracy' in transaction:\n",
    "                m_accuracy = transaction['model accuracy']\n",
    "                if m_accuracy < expected_accuracy:\n",
    "                    print(f\"Accuracy issue: Model accuracy {m_accuracy} is below threshold.\")\n",
    "                    return False  # Accuracy is not valid\n",
    "        return True  \n",
    "\n",
    "    \n",
    "    def get_last_node(self):\n",
    "        return self.chain[-1]\n",
    "\n",
    "    \n",
    "    def display_chain(self):\n",
    "        for node in self.chain:\n",
    "            print(f\"------ Session Begins --------\")\n",
    "            print(f\"Node {node.idx}: {node.hash} | Validator: {node.validator} | Proof: {node.proof}\")\n",
    "            # print(f\"Transactions: {node.transactions}\")\n",
    "            print(f\"----------------------------\")\n",
    "            print(f\"----------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import time\n",
    "import random as rand\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Node representing each block\n",
    "class Node:\n",
    "    def __init__(self, idx, prev_hash, t_stamp, transactions, proof, validator):\n",
    "        self.idx = idx\n",
    "        self.prev_hash = prev_hash\n",
    "        self.t_stamp = t_stamp\n",
    "        self.transactions = transactions\n",
    "        self.proof = proof\n",
    "        self.validator = validator\n",
    "        self.hash = self.calculate_hash()\n",
    "\n",
    "    def calculate_hash(self):\n",
    "        node_str = f\"{self.idx}{self.prev_hash}{self.t_stamp}{self.transactions}{self.proof}{self.validator}\"\n",
    "        return hashlib.sha256(node_str.encode('utf-8')).hexdigest()\n",
    "\n",
    "class Blockchain_Network:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.chain = []\n",
    "        self.transactions = []\n",
    "        self.c_node_idx = 0         \n",
    "        self.validators = ['R_Edge_Server_A', 'R_Edge_Server_B', 'R_Edge_Server_C', 'R_Edge_Server_D']\n",
    "        self.add_node()\n",
    "        self.consensus_threshold = 2  \n",
    "\n",
    "    def add_node(self):\n",
    "        # initial block\n",
    "        if self.c_node_idx == 0:\n",
    "            start_node = Node(0, \"0\", time.time(), [], 'Start', 'System')\n",
    "            self.chain.append(start_node)\n",
    "            self.c_node_idx += 1\n",
    "\n",
    "    # Simulate a transaction creation with model data and accuracy\n",
    "    def transaction_session(self, source, receiver, data, accuracy):\n",
    "        transaction = {\"AI Vendor\": source, \"Edge Device\": receiver, \"model data\": data, \"model accuracy\": accuracy}\n",
    "        self.transactions.append(transaction)\n",
    "\n",
    "        \n",
    "    # Simulate the mining process\n",
    "    def mine_node(self):\n",
    "        \n",
    "        validator = rand.choice(self.validators) \n",
    "        t_stamp = time.time()\n",
    "        \n",
    "        # Simulate proof of authority by generating a random proof\n",
    "        proof = rand.randint(150, 8500)  \n",
    "        node = Node(self.c_node_idx, self.chain[-1].hash, t_stamp, self.transactions, proof, validator)\n",
    "\n",
    "        # Check for data integrity and accuracy before adding the node\n",
    "        integrity_check = self.data_integrity(node.transactions)\n",
    "        if not integrity_check:\n",
    "            print(f\"Node {node.idx} failed the data integrity check. Node discarded.\")\n",
    "            return None\n",
    "\n",
    "        accuracy_check = self.is_valid_model(node.transactions)\n",
    "        if not accuracy_check:\n",
    "            print(f\"Node {node.idx} failed the model accuracy check. Node discarded.\")\n",
    "            return None\n",
    "\n",
    "        # Simulate validator votes for the block\n",
    "        votes = self.node_votes(node)\n",
    "        print(f\"Validator Votes: {votes}\")\n",
    "\n",
    "        if len(votes) >= self.consensus_threshold:\n",
    "            self.chain.append(node)  \n",
    "            self.c_node_idx += 1\n",
    "            self.transactions = []  # Clear transactions \n",
    "            \n",
    "            print(f\"Node {node.idx} successfully added to the blockchain.\")\n",
    "        else:          \n",
    "            print(f\"Node {node.idx} failed to reach consensus. Node discarded.\")  \n",
    "        return node\n",
    "\n",
    "    \n",
    "    # Simulate validators voting on the block   \n",
    "    def node_votes(self, node):\n",
    "        votes = []\n",
    "        \n",
    "        for validator in self.validators:\n",
    "            if self.data_integrity(node.transactions) and self.is_valid_model(node.transactions):\n",
    "                votes.append(validator)\n",
    "                \n",
    "        return votes\n",
    "\n",
    "        \n",
    "    def data_integrity(self, transactions):\n",
    "        \"\"\"\n",
    "        Checks for missing values, duplicates, and incorrect data in transactions.\n",
    "        \"\"\"\n",
    "        # Check for missing values, duplicates, and incorrect data\n",
    "        for transaction in transactions:\n",
    "            # Assuming 'model data' is a numeric value, or convert it into a pandas dataframe if needed\n",
    "            if isinstance(transaction['model data'], pd.DataFrame):\n",
    "                missing_values = transaction['model data'].isnull().sum().sum()\n",
    "                duplicate_values = transaction['model data'].duplicated().sum()\n",
    "                incorrect_data = 0\n",
    "                # Check for incorrect data types (for example, if expected to be numeric)\n",
    "                for col in transaction['model data'].select_dtypes(include=[np.number]).columns:\n",
    "                    if not pd.api.types.is_numeric_dtype(transaction['model data'][col]):\n",
    "                        incorrect_data += 1\n",
    "                \n",
    "                # Check if there are any issues\n",
    "                if missing_values > 0 or duplicate_values > 0 or incorrect_data > 0:\n",
    "                    return False\n",
    "            else:\n",
    "                # Assuming model data is numeric\n",
    "                if not isinstance(transaction['model data'], (int, float)):\n",
    "                    return False\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def is_valid_model(self, transactions):\n",
    "        \"\"\"\n",
    "        Checks if the model accuracy is above the expected threshold.\n",
    "        \"\"\"\n",
    "        expected_m_accuracy = 80 \n",
    "        \n",
    "        for transaction in transactions:\n",
    "            if 'model accuracy' in transaction:\n",
    "                m_accuracy = transaction['model accuracy']\n",
    "                # Ensure accuracy is above the threshold\n",
    "                if m_accuracy < expected_m_accuracy:\n",
    "                    return False\n",
    "        \n",
    "        return True  \n",
    "\n",
    "    def get_last_node(self):\n",
    "        return self.chain[-1]\n",
    "\n",
    "    \n",
    "    def display_chain(self):\n",
    "        for node in self.chain:\n",
    "            print(f\"##### Session Starts ####\")\n",
    "            print(f\"Node {node.idx}: {node.hash} | Validator: {node.validator} | Proof: {node.proof}\")\n",
    "            print(f\"----------------------------\")\n",
    "\n",
    "# Example usage\n",
    "blockchain = Blockchain_Network()\n",
    "blockchain.transaction_session('AI_Vendor_X', 'Edge_Device_1', 100, 85)  # Add a transaction with model data and accuracy\n",
    "blockchain.mine_node()  # Mine the node and check content matching\n",
    "blockchain.display_chain()  # Display the blockchain\n",
    "blockchain.transaction_session('AI_Vendor_Y', 'Edge_Device_2', 150, 90)\n",
    "blockchain.mine_node()  # Mine the node and check content matching\n",
    "blockchain.display_chain()  # Display the blockchain\n",
    "blockchain.transaction_session('AI_Vendor_Y', 'Edge_Device_2', 150, 70)  # Add another transaction with model data and accuracy\n",
    "\n",
    "\n",
    "blockchain.mine_node()  # Mine the node and check content matching\n",
    "blockchain.display_chain()  # Display the blockchain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import time\n",
    "import random as rand\n",
    "\n",
    "# node representing each block\n",
    "class Node:\n",
    "    def __init__(self, idx, prev_hash, t_stamp, transactions, proof, validator):\n",
    "        self.idx = idx\n",
    "        self.prev_hash = prev_hash\n",
    "        self.t_stamp = t_stamp\n",
    "        self.transactions = transactions\n",
    "        self.proof = proof\n",
    "        self.validator = validator\n",
    "        self.hash = self.calculate_hash()\n",
    "\n",
    "    def calculate_hash(self):\n",
    "        node_str = f\"{self.idx}{self.prev_hash}{self.t_stamp}{self.transactions}{self.proof}{self.validator}\"\n",
    "        return hashlib.sha256(node_str.encode('utf-8')).hexdigest()\n",
    "        \n",
    "class Blockchain_Network:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.chain = []\n",
    "        self.transactions = []\n",
    "        self.c_node_idx = 0         \n",
    "        self.validators = ['R_Edge_Server_A', 'R_Edge_Server_B', 'R_Edge_Server_C', 'R_Edge_Server_D']\n",
    "        self.add_node()\n",
    "        self.consensus_threshold = 2  \n",
    "\n",
    "    def add_node(self):\n",
    "        # initial block\n",
    "        if self.c_node_idx == 0:\n",
    "            start_node = Node(0, \"0\", time.time(), [], 'Start', 'System')\n",
    "            self.chain.append(start_node)\n",
    "            self.c_node_idx += 1\n",
    "\n",
    "    # simulate a transaction creation  data: model's data, accuracy: model's accuracy\n",
    "    def transaction_session(self, source, receiver, data, accuracy):\n",
    "        transaction = {\"AI Vendor\": source, \"Edge Device\": receiver, \"model data\": data, \"model accuracy\": accuracy}\n",
    "        self.transactions.append(transaction)\n",
    "\n",
    "        \n",
    "    # Simulate the mining process\n",
    "    def mine_node(self):\n",
    "        \n",
    "        validator = rand.choice(self.validators) \n",
    "        t_stamp = time.time()\n",
    "        \n",
    "        # Simulate proof of authority by generating a random proof\n",
    "        proof = rand.randint(150, 8500)  \n",
    "        node = Node(self.c_node_idx, self.chain[-1].hash, t_stamp, self.transactions, proof, validator)\n",
    "\n",
    "        # Check for data integrity and accuracy before adding the node\n",
    "        integrity_check = self.data_integrity(node.transactions)\n",
    "        if not integrity_check:\n",
    "            print(f\"Node {node.idx} failed the data integrity check. Node discarded.\")\n",
    "            return None\n",
    "\n",
    "        accuracy_check = self.is_valid_model(node.transactions)\n",
    "        if not accuracy_check:\n",
    "            print(f\"Node {node.idx} failed the model accuracy check. Node discarded.\")\n",
    "            return None\n",
    "\n",
    "        # Simulate validator votes for the block\n",
    "        votes = self.node_votes(node)\n",
    "        print(f\"Validator Votes: {votes}\")\n",
    "\n",
    "        if len(votes) >= self.consensus_threshold and (integrity_check and accuracy_check is True):\n",
    "            self.chain.append(node)  \n",
    "            self.c_node_idx += 1\n",
    "            self.transactions = [] \n",
    "            \n",
    "            print(f\"Node {node.idx} successfully added to the blockchain.\")\n",
    "        else:          \n",
    "            print(f\"Node {node.idx} failed to reach consensus. Node discarded.\")  \n",
    "        return node\n",
    "\n",
    "    \n",
    "     # Simulate validators voting on the block   \n",
    "    def node_votes(self, node):\n",
    "        votes = []\n",
    "        \n",
    "        for validator in self.validators:\n",
    "            if self.data_integrity(node.transactions) and self.is_valid_model(node.transactions):\n",
    "                votes.append(validator)\n",
    "            # voters = rand.choice([True, False])\n",
    "            # if voters and  self.data_integrity(node.transactions) and self.is_valid_model(node.transactions) is True:\n",
    "            #         votes.append(validator)\n",
    "                \n",
    "            # if self.data_integrity(node.transactions):\n",
    "            #     if self.is_valid_model(node.transactions):\n",
    "                    # votes.append(validator)\n",
    "            \n",
    "            # if rand.choice([True, False]):\n",
    "            #     votes.append(validator)     \n",
    "        \n",
    "        return votes\n",
    "\n",
    "        \n",
    "    def data_integrity(self, transactions):\n",
    "        \n",
    "        # accuracy, consistency, data mismatch, and outliers \n",
    "        for transaction in transactions:\n",
    "   \n",
    "            if 'model data' in transaction:\n",
    "                data = transaction['model data']\n",
    "                missing_values = data.isnull().sum().sum()\n",
    "                duplicate_values = data.duplicated().sum()\n",
    "                incorrect_data = 0\n",
    "                # outliers = 0\n",
    "                \n",
    "                for col in data.select_dtypes(include=[np.number]).columns:\n",
    "                    if not pd.api.types.is_numeric_dtype(data[col]):\n",
    "                        incorrect_data += 1\n",
    "                        \n",
    "                # for col in data.select_dtypes(include=[np.number]).columns:\n",
    "                #     mean = data[col].mean()\n",
    "                #     std_dev = data[col].std()\n",
    "                #     outliers_in_col = data[(data[col] < mean - 3*std_dev) | (data[col] > mean + 3 *std_dev)]\n",
    "                #     outliers += outliers_in_col.shape[0] \n",
    "                    \n",
    "                # print(f\"Integrity check results - Missing data: {missing_values}, Duplicates: {duplicate_values}, Incorrect data: {incorrect_data}, Outliers: {outliers}\")\n",
    "                # print(f\"Integrity check results - Missing data: {missing_values}, Duplicates: {duplicate_values}, Incorrect data: {incorrect_data}\")\n",
    "                # if missing_values > 0 or duplicate_values > 0 or incorrect_data > 0 or outliers > 0:\n",
    "                if missing_values > 0 or duplicate_values > 0 or incorrect_data > 0:\n",
    "                    return False\n",
    "                return True\n",
    "            \n",
    "        \n",
    "    def is_valid_model(self, transactions):\n",
    "        expected_m_accuracy = 80 \n",
    "       \n",
    "        for transaction in transactions:\n",
    "            if 'accuracy' in transaction:\n",
    "                m_accuracy = transaction['accuracy']\n",
    "                m_accuracy >=  expected_m_accuracy \n",
    "                return False\n",
    "            return True  \n",
    "\n",
    "\n",
    "    def get_last_node(self):\n",
    "        return self.chain[-1]\n",
    "\n",
    "    \n",
    "    def display_chain(self):\n",
    "        for node in self.chain:\n",
    "            print(f\"##### Session Starts ####\")\n",
    "            print(f\"Node {node.idx}: {node.hash} | Validator: {node.validator} | Proof: {node.proof}\")\n",
    "            # print(f\"Transactions: {node.transactions}\")\n",
    "            # print(f\"##### Session Ends ####\")\n",
    "            print(f\"----------------------------\")\n",
    "            # print(f\"---Updated block chain------\")\n",
    "            # print(f\"############################\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        #  \n",
    "        # missing_values = data.isnull().sum().sum()\n",
    "        # duplicate_values = data.duplicated().sum()\n",
    "        \n",
    "        # incorrect_data = 0\n",
    "        # outliers = 0\n",
    "        \n",
    "        # for col in data.select_dtypes(include=[np.number]).columns:\n",
    "        #     if not pd.api.types.is_numeric_dtype(data[col]):\n",
    "        #         incorrect_data += 1\n",
    "                \n",
    "        # for col in data.select_dtypes(include=[np.number]).columns:\n",
    "        #     mean = data[col].mean()\n",
    "        #     std_dev = data[col].std()\n",
    "        #     outliers_in_col = data[(data[col] < mean - 3*std_dev) | (data[col] > mean + 3*std_dev)]\n",
    "        #     outliers += outliers_in_col.shape[0] \n",
    "       \n",
    "        # print(f\"Integrity check results - Missing data: {missing_values}, Duplicates: {duplicate_values}, Incorrect data: {incorrect_data}, Outliers: {outliers}\")\n",
    "        \n",
    "        # if missing_values > 0 or duplicate_values > 0 or incorrect_data > 0 or outliers > 0:\n",
    "        #     return False\n",
    "        # return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_integrity(data):\n",
    "    \n",
    "    # accuracy, consistency, data mismatch, and outliers \n",
    "    missing_values = data.isnull().sum().sum()\n",
    "    duplicate_values = data.duplicated().sum()\n",
    "    \n",
    "    incorrect_data = 0\n",
    "    outliers = 0\n",
    "    \n",
    "    for col in data.select_dtypes(include=[np.number]).columns:\n",
    "        if not pd.api.types.is_numeric_dtype(data[col]):\n",
    "            incorrect_data += 1\n",
    "\n",
    "    for col in data.select_dtypes(include=[np.number]).columns:\n",
    "            mean = data[col].mean()\n",
    "            std_dev = data[col].std()\n",
    "            outliers_in_col = data[(data[col] < mean - 3*std_dev) | (data[col] > mean + 3*std_dev)]\n",
    "            outliers += outliers_in_col.shape[0] \n",
    "        \n",
    "    # Print out the results\n",
    "    print(f\"Missing Values: {missing_values}\")\n",
    "    print(f\"Duplicate Rows: {duplicate_values}\")\n",
    "    print(f\"Incorrect Data Type Columns: {incorrect_data}\")\n",
    "    print(f\"Outlier Values: {outliers}\")\n",
    "\n",
    "    return missing_values, duplicate_values, incorrect_data, outliers\n",
    "\n",
    "# Example usage:\n",
    "# Assuming you have a pandas DataFrame `df`\n",
    "# df = pd.read_csv('your_data.csv')\n",
    "# missing_values, duplicate_values = check_data_integrity(df)\n",
    "\n",
    "data = Occupancy\n",
    "\n",
    "missing_values, duplicate_values, incorrect_data, outliers = data_integrity(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "powerConsumption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Occupancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets\n",
    "activity_wsdata = pd.read_csv('C:/Users/moyin/Downloads/data/activity data.csv')\n",
    "\n",
    "target = 'activity'\n",
    "X = activity_wsdata.drop(columns=[target])\n",
    "y = activity_wsdata[target]\n",
    "\n",
    "# split data\n",
    "WS_train, WS_test, ws_train, ws_test = train_test_split(X, y, test_size=0.5, random_state=42)\n",
    "data_train, data_test, goal_train, goal_test = train_test_split(X_train, y_train, test_size=0.5, random_state=42)\n",
    "e_Device_X, e_Data_X, e_Device_Y, e_Data_Y = train_test_split(model_train, target_train, train_size=0.5, random_state=42)\n",
    "e_Server1_X, e_Server2_X, e_Server1_Y, e_Server2_Y = train_test_split(edgeDevice_X, edgeData_X, train_size=0.5, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# activity_wsdata['activity'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(X_train))\n",
    "print(len(model_train))\n",
    "print(len(edgeDevice_X))\n",
    "print(len(edgeServer1_X))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import time\n",
    "import random as rand\n",
    "\n",
    "# node representing each block\n",
    "class Node:\n",
    "    def __init__(self, idx, prev_hash, t_stamp, transactions, proof, validator):\n",
    "        self.idx = idx\n",
    "        self.prev_hash = prev_hash\n",
    "        self.t_stamp = t_stamp\n",
    "        self.transactions = transactions\n",
    "        self.proof = proof\n",
    "        self.validator = validator\n",
    "        self.hash = self.calculate_hash()\n",
    "\n",
    "    def calculate_hash(self):\n",
    "        node_str = f\"{self.idx}{self.prev_hash}{self.t_stamp}{self.transactions}{self.proof}{self.validator}\"\n",
    "        return hashlib.sha256(node_str.encode('utf-8')).hexdigest()\n",
    "        \n",
    "class Blockchain_Network:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.chain = []\n",
    "        self.transactions = []\n",
    "        self.c_node_idx = 0         \n",
    "        self.validators = ['R_Edge_Server_A', 'R_Edge_Server_B', 'R_Edge_Server_C', 'R_Edge_Server_D']\n",
    "        self.add_node()\n",
    "        # minimum number of validators required for the consensus\n",
    "        self.consensus_threshold = 2\n",
    "\n",
    "    def add_node(self):\n",
    "        # initial block\n",
    "        if self.c_node_idx == 0:\n",
    "            start_node = Node(0, \"0\", time.time(), [], 'Start', 'System')\n",
    "            self.chain.append(start_node)\n",
    "            self.c_node_idx += 1\n",
    "\n",
    "    # simulate a transaction creation - # amt: data size of the AI model parameter\n",
    "    def transaction_session(self, source, receiver, data):\n",
    "        transaction = {\"AI Vendor\": source, \"Edge Device\": receiver, \"model data\": data}\n",
    "        self.transactions.append(transaction)\n",
    "        \n",
    "    # Simulate the mining process\n",
    "    def mine_node(self):\n",
    "        \n",
    "        validator = rand.choice(self.validators) \n",
    "        t_stamp = time.time()\n",
    "        \n",
    "        # Simulate proof of authority by generating a random proof\n",
    "        proof = rand.randint(150, 850000)  \n",
    "        node = Node(self.c_node_idx, self.chain[-1].hash, t_stamp, self.transactions, proof, validator)\n",
    "        \n",
    "        # Simulate validator votes for the block\n",
    "        votes = self.node_votes(node)\n",
    "        print(votes)\n",
    "\n",
    "        if len(votes) >= self.consensus_threshold:\n",
    "            self.chain.append(node)  \n",
    "            self.c_node_idx += 1\n",
    "            self.transactions = [] \n",
    "            \n",
    "            print(f\"Node {node.idx} successfully added to the blockchain.\")\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            print(f\"Node {node.idx} failed to reach consensus. Block discarded.\")\n",
    "        \n",
    "        # self.chain.append(node)\n",
    "        # self.c_node_idx += 1\n",
    "        # self.transactions = []  \n",
    "        return node\n",
    "\n",
    "    def node_votes(self, node):\n",
    "        # Simulate validators voting on the block. Each validator votes based on the block's validator.\n",
    "        votes = []\n",
    "        \n",
    "        for validator in self.validators:\n",
    "            # Validators check if the node's content match \n",
    "            if self.is_valid_mparameter(node.transactions):\n",
    "                \n",
    "                votes.append(validator)\n",
    "        \n",
    "        return votes\n",
    "\n",
    "        # works for making the decision using randomization\n",
    "        # for validator in self.validators:\n",
    "        #     # Validators vote if they are not the one who created the block\n",
    "        #     if rand.choice([True, False]):\n",
    "                \n",
    "        #         votes.append(validator)\n",
    "                \n",
    "        # return votes\n",
    "        \n",
    "    def is_valid_mparameter(self, transactions):\n",
    "\n",
    "        expected_model_accuracy = 10 # confirm the value is percentage or decimal\n",
    "        \n",
    "        # Use model accuracy in this variable. Cons: it uses numeric validation (verification is solely based on the model's accuracy figure, not the content).\n",
    "        # Will work best when a single model is sent to the edge servers for verification\n",
    "        \n",
    "        for transaction in transactions:\n",
    "            if transaction['data'] != expected_model_accuracy: # either use if not or use a lowerbound figure to eliminate the models.\n",
    "                return False  \n",
    "        return True  \n",
    "    \n",
    "    def get_last_node(self):\n",
    "        return self.chain[-1]\n",
    "\n",
    "    \n",
    "    def display_chain(self):\n",
    "        for node in self.chain:\n",
    "            # print(f\"##### Session Starts ####\")\n",
    "            print(f\"Node {node.idx}: {node.hash} | Validator: {node.validator} | Proof: {node.proof}\")\n",
    "            # print(f\"Transactions: {node.transactions}\")\n",
    "            print(f\"##### Session Ends ####\")\n",
    "            print(f\"----------------------------\")\n",
    "            # print(f\"---Updated block chain------\")\n",
    "            # print(f\"############################\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the blockchain\n",
    "PoA_consensus = Blockchain_Network()\n",
    "\n",
    "# Simulate creating transactions\n",
    "    # source: AI Marketplace represented as App_VendorID\n",
    "    # receiver: edge devices defined as ED_RegionID_DeviceID where ED represents the edge device\n",
    "\n",
    "# Display the updated blockchain\n",
    "PoA_consensus.display_chain()\n",
    "\n",
    "# convert the data to a single array representing the dataset...\n",
    "PoA_consensus.transaction_session(\"App_V01\", \"ED_R1_AR1\", model_train)\n",
    "PoA_consensus.transaction_session(\"App_V01\", \"ED_R2_AR2\", WS_train)\n",
    "\n",
    "# Mine another block\n",
    "PoA_consensus.mine_node()\n",
    "\n",
    "# # Display the updated blockchain\n",
    "# PoA_consensus.display_chain()\n",
    "\n",
    "PoA_consensus.transaction_session(\"App_V03\", \"ED_R4_AR1\", edgeDevice_X)\n",
    "PoA_consensus.transaction_session(\"App_V04\", \"ED_R3_AR2\", data_train)\n",
    "\n",
    "# Mine another block\n",
    "PoA_consensus.mine_node()\n",
    "\n",
    "# # Display the updated blockchain\n",
    "# PoA_consensus.display_chain()\n",
    "\n",
    "PoA_consensus.transaction_session(\"App_V02\", \"ED_R1_AR2\", e_Device_X)\n",
    "PoA_consensus.transaction_session(\"App_V02\", \"ED_R1_AR4\", edgeServer1_X)\n",
    "\n",
    "# Mine another block\n",
    "PoA_consensus.mine_node()\n",
    "\n",
    "# # Display the updated blockchain\n",
    "# PoA_consensus.display_chain()\n",
    "\n",
    "PoA_consensus.transaction_session(\"App_V05\", \"ED_R2_AR3\", e_Server1_X)\n",
    "PoA_consensus.transaction_session(\"App_V01\", \"ED_R1_AR5\", edgeServer2_X)\n",
    "\n",
    "# Simulate mining a block\n",
    "mined_node = PoA_consensus.mine_node()\n",
    "\n",
    "# # Display the blockchain\n",
    "# PoA_consensus.display_chain()\n",
    "\n",
    "PoA_consensus.transaction_session(\"App_V02\", \"ED_R4_AR1\", edgeDevice_X)\n",
    "PoA_consensus.transaction_session(\"App_V05\", \"ED_R1_AR2\", WS_train)\n",
    "\n",
    "# # Mine another block\n",
    "# PoA_consensus.mine_node()\n",
    "\n",
    "# # Display the updated blockchain\n",
    "# PoA_consensus.display_chain()\n",
    "\n",
    "PoA_consensus.transaction_session(\"App_V01\", \"ED_R2_AR1\", e_Server1_X)\n",
    "PoA_consensus.transaction_session(\"App_V02\", \"ED_R4_AR4\", model_train)\n",
    "\n",
    "# Mine another block\n",
    "PoA_consensus.mine_node()\n",
    "\n",
    "# # Display the updated blockchain\n",
    "# PoA_consensus.display_chain()\n",
    "\n",
    "PoA_consensus.transaction_session(\"App_V04\", \"ED_R4_AR1\", edgeDevice_X)\n",
    "PoA_consensus.transaction_session(\"App_V05\", \"ED_R2_AR3\", X_train)\n",
    "\n",
    "# Mine another block\n",
    "PoA_consensus.mine_node()\n",
    "\n",
    "# # Display the updated blockchain\n",
    "# PoA_consensus.display_chain()\n",
    "\n",
    "PoA_consensus.transaction_session(\"App_V03\", \"ED_R3_AR5\", e_Data_X)\n",
    "PoA_consensus.transaction_session(\"App_V01\", \"ED_R1_AR2\", edgeData_X)\n",
    "\n",
    "# Mine another block\n",
    "PoA_consensus.mine_node()\n",
    "\n",
    "# Display the updated blockchain\n",
    "PoA_consensus.display_chain()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# things to note\n",
    "# the voting is randomized, so the key decision factor used is the consensus threshold\n",
    "# the actual data being passed to it at this point, isn't being reflected. because it is actually not checking the data.\n",
    "## the validator is deciding based on the randomized number of votes present at a given time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def validate_dataset(df):\n",
    "    \"\"\"\n",
    "    Validates the given dataset (Pandas DataFrame) for the following conditions:\n",
    "    - No missing values in required columns\n",
    "    - Correct data types\n",
    "    - Age should be an integer within a valid range\n",
    "    - Name should not be empty and should consist of alphabets\n",
    "\n",
    "    Args:\n",
    "    df (pd.DataFrame): The dataset to validate\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary with validation results\n",
    "    \"\"\"\n",
    "    validation_results = {\n",
    "        \"missing_values\": {},\n",
    "        \"invalid_data_types\": {},\n",
    "        \"invalid_ages\": [],\n",
    "        \"invalid_names\": []\n",
    "    }\n",
    "\n",
    "    # Check for missing values in specific columns\n",
    "    required_columns = ['id', 'name', 'age']\n",
    "    for col in required_columns:\n",
    "        missing = df[col].isnull().sum()\n",
    "        if missing > 0:\n",
    "            validation_results['missing_values'][col] = missing\n",
    "\n",
    "    # Check data types\n",
    "    if not pd.api.types.is_integer_dtype(df['age']):\n",
    "        validation_results['invalid_data_types']['age'] = 'Expected integer type for age'\n",
    "\n",
    "    if not pd.api.types.is_string_dtype(df['name']):\n",
    "        validation_results['invalid_data_types']['name'] = 'Expected string type for name'\n",
    "\n",
    "    # Check for invalid age values (e.g., not an integer, or out of range)\n",
    "    for index, row in df.iterrows():\n",
    "        if not (18 <= row['age'] <= 100):\n",
    "            validation_results['invalid_ages'].append((index, row['age']))\n",
    "\n",
    "    # Check for invalid name values (e.g., empty string or non-alphabet characters)\n",
    "    for index, row in df.iterrows():\n",
    "        if not row['name'].isalpha():\n",
    "            validation_results['invalid_names'].append((index, row['name']))\n",
    "\n",
    "    return validation_results\n",
    "\n",
    "# Example usage:\n",
    "data = {\n",
    "    'id': [1, 2, 3, 4],\n",
    "    'name': ['Alice', 'Bob', '1234', 'Charlie'],\n",
    "    'age': [25, 32, 101, None]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "validation_result = validate_dataset(df)\n",
    "print(validation_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "class Block:\n",
    "    def __init__(self, index, previous_hash, timestamp, transactions, proof, validator):\n",
    "        self.index = index\n",
    "        self.previous_hash = previous_hash\n",
    "        self.timestamp = timestamp\n",
    "        self.transactions = transactions\n",
    "        self.proof = proof\n",
    "        self.validator = validator\n",
    "        self.hash = self.calculate_hash()\n",
    "\n",
    "    def calculate_hash(self):\n",
    "        block_string = f\"{self.index}{self.previous_hash}{self.timestamp}{self.transactions}{self.proof}{self.validator}\"\n",
    "        return hashlib.sha256(block_string.encode('utf-8')).hexdigest()\n",
    "\n",
    "class Blockchain:\n",
    "    def __init__(self, df):\n",
    "        self.chain = []\n",
    "        self.transactions = []\n",
    "        self.current_block_index = 0\n",
    "        self.validators = [\"Validator1\", \"Validator2\", \"Validator3\"]  # List of validators\n",
    "        self.df = df  # DataFrame with valid transaction data (including amount and content)\n",
    "        self.add_block()\n",
    "        self.consensus_threshold = 2  # Minimum number of validators to approve a block\n",
    "\n",
    "    def add_block(self):\n",
    "        # Add the genesis block\n",
    "        if self.current_block_index == 0:\n",
    "            genesis_block = Block(0, \"0\", time.time(), [], \"genesis\", \"System\")\n",
    "            self.chain.append(genesis_block)\n",
    "            self.current_block_index += 1\n",
    "\n",
    "    def create_transaction(self, sender, recipient, amount, content):\n",
    "        # Simulate creating a transaction\n",
    "        transaction = {\"sender\": sender, \"recipient\": recipient, \"amount\": amount, \"content\": content}\n",
    "        self.transactions.append(transaction)\n",
    "\n",
    "    def mine_block(self):\n",
    "        # Simulate the mining process with consensus based on matching amounts and content\n",
    "        validator = random.choice(self.validators)  # Randomly select a validator\n",
    "        timestamp = time.time()\n",
    "        proof = random.randint(0, 1000000)  # Simulate proof of authority by generating a random proof\n",
    "        block = Block(self.current_block_index, self.chain[-1].hash, timestamp, self.transactions, proof, validator)\n",
    "        \n",
    "        # Simulate validator votes for the block based on matching amounts and content\n",
    "        votes = self.get_votes_for_block(block)\n",
    "\n",
    "        if len(votes) >= self.consensus_threshold:\n",
    "            self.chain.append(block)  # Add block to chain if it reaches consensus\n",
    "            self.current_block_index += 1\n",
    "            self.transactions = []  # Reset transactions after mining\n",
    "            print(f\"Block {block.index} successfully added to the blockchain.\")\n",
    "        else:\n",
    "            print(f\"Block {block.index} failed to reach consensus. Block discarded.\")\n",
    "        \n",
    "        return block\n",
    "\n",
    "    def get_votes_for_block(self, block):\n",
    "        # Simulate validators voting on the block based on matching amounts and content\n",
    "        votes = []\n",
    "        for validator in self.validators:\n",
    "            # Validators check if the block's transactions match expected amounts and content in the DataFrame\n",
    "            if self.is_valid_transaction(block.transactions):\n",
    "                votes.append(validator)\n",
    "        return votes\n",
    "\n",
    "    def is_valid_transaction(self, transactions):\n",
    "        # In this scenario, we'll define valid transactions as those that match both the amount and content in the DataFrame\n",
    "        for transaction in transactions:\n",
    "            amount_match = self.df[self.df['amount'] == transaction['amount']]\n",
    "            content_match = self.df[(self.df['amount'] == transaction['amount']) & \n",
    "                                    (self.df['content'] == transaction['content'])]\n",
    "            if amount_match.empty or content_match.empty:\n",
    "                return False  # Reject the block if any transaction doesn't match the DataFrame criteria\n",
    "        return True  # Accept the block if all transactions match the expected amount and content\n",
    "\n",
    "    def get_last_block(self):\n",
    "        return self.chain[-1]\n",
    "\n",
    "    def display_chain(self):\n",
    "        for block in self.chain:\n",
    "            print(f\"Block {block.index}: {block.hash} | Validator: {block.validator} | Proof: {block.proof}\")\n",
    "            print(f\"Transactions: {block.transactions}\")\n",
    "            print(f\"----------------------------\")\n",
    "\n",
    "# Sample DataFrame with valid transaction data (amounts and contents)\n",
    "data = {\n",
    "    'sender': ['Alice', 'Bob', 'Charlie'],\n",
    "    'recipient': ['Bob', 'Charlie', 'Alice'],\n",
    "    'amount': [10, 10, 10],  # Expected amounts\n",
    "    'content': ['Payment for service', 'Payment for goods', 'Payment for service']  # Expected content\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Test the blockchain with consensus based on matching amounts and content\n",
    "poa_blockchain = Blockchain(df)\n",
    "\n",
    "# Simulate creating transactions\n",
    "poa_blockchain.create_transaction(\"Alice\", \"Bob\", 10, \"Payment for service\")\n",
    "poa_blockchain.create_transaction(\"Bob\", \"Charlie\", 10, \"Payment for goods\")\n",
    "\n",
    "# Simulate mining a block with consensus\n",
    "poa_blockchain.mine_block()\n",
    "\n",
    "# Display the blockchain after mining\n",
    "poa_blockchain.display_chain()\n",
    "\n",
    "# Simulate more transactions and mining\n",
    "poa_blockchain.create_transaction(\"Charlie\", \"Alice\", 10, \"Payment for service\")\n",
    "poa_blockchain.create_transaction(\"Alice\", \"Bob\", 10, \"Payment for service\")\n",
    "\n",
    "# Simulate mining another block with consensus\n",
    "poa_blockchain.mine_block()\n",
    "\n",
    "# Display the updated blockchain\n",
    "poa_blockchain.display_chain()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Step 4: Initialize the model (Logistic Regression)\n",
    "# model = LogisticRegression(max_iter=200)\n",
    "\n",
    "# # Step 5: Train the model using the training data\n",
    "# model.fit(X_train, y_train)\n",
    "\n",
    "# # Step 6: Make predictions on the test set\n",
    "# y_pred = model.predict(X_test)\n",
    "\n",
    "# # Step 7: Evaluate the model (Accuracy)\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "# print(f\"Model Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def displayInfo (training, edge1, edge2, edge3, edge4):\n",
    "    print (\"Precision on Training Data: \", training)\n",
    "    print (\"Precision on edge1 Data: \", edge1)\n",
    "    print (\"Precision on edge2 Data: \", edge2)\n",
    "    print (\"Precision on edge3 Data: \", edge3)\n",
    "    print (\"Precision on edge4 Data: \", edge4)\n",
    "\n",
    "def calculateAccuracy (Y_predicted, Y_true, datasetType: str, model):\n",
    "    if datasetType == \"Categorical\":\n",
    "        return metrics.precision_score(Y_true, Y_predicted,average='macro')\n",
    "    return metrics.mean_squared_error(Y_true, Y_predicted)\n",
    "\n",
    "\n",
    "def runModel(model, X_test, Y_test,datasetType: str): \n",
    "    Y_predicted = model.predict(X_test)\n",
    "    return calculateAccuracy (Y_predicted, Y_test,datasetType, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models\n",
    "def trainCategoricalModel (X,Y):\n",
    "    return LogisticRegression().fit(X, Y)\n",
    "\n",
    "def trainCatergoricalModel_ (X,Y):\n",
    "    return GaussianNB().fit(X, Y)\n",
    "\n",
    "def trainCatModel (X,Y):\n",
    "    model  = svm.SVC(kernel='linear')\n",
    "    return model.fit(X, Y)\n",
    "\n",
    "def trainContinuousModel (X,Y):\n",
    "    return LinearRegression().fit(X, Y)\n",
    "\n",
    "def trainContinuousModel_ (X,Y):\n",
    "    Y = Y.astype('int')\n",
    "    model = KNeighborsClassifier(n_neighbors=1)\n",
    "    return model.fit(X,Y)\n",
    "\n",
    "def trainConModel(X,Y):\n",
    "    Y = Y.astype('int')\n",
    "    model = RandomForestRegressor(n_estimators= 1000, random_state=42)\n",
    "    return model.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData (df,predictName: str,datasetType: str):\n",
    "\n",
    "    X = df.drop(columns=[predictName])  \n",
    "    y = df[predictName]                \n",
    "    \n",
    "    # First split: Split data into two halves (50% training and 50% for further splits)\n",
    "    model_train_X, X_remaining, model_train_Y, y_remaining = train_test_split(X, y, train_size=0.5, random_state=42)\n",
    "    \n",
    "    # Second split: Split the remaining data into 2 (50% for edge server 1 and 50% for edge server 2)\n",
    "    edgeServer1_X, edgeServer2_X, edgeServer1_Y, edgeServer2_Y = train_test_split(X_remaining, y_remaining, train_size=0.5, random_state=42)\n",
    "    \n",
    "    # Third split: Split the remaining data into 2 (50% for edge server 3 and 50% for edge server 4)\n",
    "    edgeServer3_X, edgeServer4_X, edgeServer3_Y, edgeServer4_Y = train_test_split(X_remaining, y_remaining, train_size=0.5, random_state=42)\n",
    "    \n",
    "    if datasetType == \"Categorical\":\n",
    "        model = trainCategoricalModel (model_train_X, model_train_Y)\n",
    "        \n",
    "    else:\n",
    "        model = trainContinuousModel (model_train_X, model_train_Y)\n",
    "        \n",
    "        \n",
    "    trainingAccuacy, edgeServer1Accuracy, edgeServer2Accuracy, edgeServer3Accuracy, edgeServer4Accuracy = runModel (model, model_train_X, model_train_Y,datasetType), runModel(model,edgeServer1_X, edgeServer1_Y,datasetType), runModel(model,edgeServer2_X, edgeServer2_Y,datasetType), runModel(model,edgeServer3_X, edgeServer3_Y,datasetType), runModel(model,edgeServer4_X, edgeServer4_Y,datasetType)\n",
    "\n",
    "    return trainingAccuacy, edgeServer1Accuracy, edgeServer2Accuracy, edgeServer3Accuracy, edgeServer4Accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loaddata (df,predictName: str,datasetType: str):\n",
    "    \n",
    "    X = df.drop(columns=[predictName])  \n",
    "    y = df[predictName]                \n",
    "    \n",
    "    # First split: Split data into two halves (50% training and 50% for further splits)\n",
    "    model_train_X, X_remaining, model_train_Y, y_remaining = train_test_split(X, y, train_size=0.5, random_state=42)\n",
    "    \n",
    "    # Second split: Split the remaining data into 2 (50% for edge server 1 and 50% for edge server 2)\n",
    "    edgeServer1_X, edgeServer2_X, edgeServer1_Y, edgeServer2_Y = train_test_split(X_remaining, y_remaining, train_size=0.5, random_state=42)\n",
    "    \n",
    "    # Third split: Split the remaining data into 2 (50% for edge server 3 and 50% for edge server 4)\n",
    "    edgeServer3_X, edgeServer4_X, edgeServer3_Y, edgeServer4_Y = train_test_split(X_remaining, y_remaining, train_size=0.5, random_state=42)\n",
    "    \n",
    "    if datasetType == \"Categorical\":\n",
    "        \n",
    "        model_a = trainCatergoricalModel_(model_train_X, model_train_Y)\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        model_a = trainContinuousModel_(model_train_X, model_train_Y)   \n",
    "    \n",
    "\n",
    "    training_A, edgeServer1_A, edgeServer2_A, edgeServer3_A, edgeServer4_A = runModel (model_a, model_train_X, model_train_Y,datasetType), runModel(model_a,edgeServer1_X, edgeServer1_Y,datasetType), runModel(model_a,edgeServer2_X, edgeServer2_Y,datasetType), runModel(model_a,edgeServer3_X, edgeServer3_Y,datasetType), runModel(model_a,edgeServer4_X, edgeServer4_Y,datasetType)\n",
    "    \n",
    "    return training_A, edgeServer1_A, edgeServer2_A, edgeServer3_A, edgeServer4_A\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data (df,predictName: str,datasetType: str):\n",
    "    \n",
    "    X = df.drop(columns=[predictName])  \n",
    "    y = df[predictName]                \n",
    "    \n",
    "    # First split: Split data into two halves (50% training and 50% for further splits)\n",
    "    model_train_X, X_remaining, model_train_Y, y_remaining = train_test_split(X, y, train_size=0.5, random_state=42)\n",
    "    \n",
    "    # Second split: Split the remaining data into 2 (50% for edge server 1 and 50% for edge server 2)\n",
    "    edgeServer1_X, edgeServer2_X, edgeServer1_Y, edgeServer2_Y = train_test_split(X_remaining, y_remaining, train_size=0.5, random_state=42)\n",
    "    \n",
    "    # Third split: Split the remaining data into 2 (50% for edge server 3 and 50% for edge server 4)\n",
    "    edgeServer3_X, edgeServer4_X, edgeServer3_Y, edgeServer4_Y = train_test_split(X_remaining, y_remaining, train_size=0.5, random_state=42)\n",
    "\n",
    "    \n",
    "    if datasetType == \"Categorical\":\n",
    "        \n",
    "        model_b = trainCatModel(model_train_X, model_train_Y)\n",
    "        \n",
    "    else:\n",
    "       \n",
    "        model_b = trainConModel(model_train_X, model_train_Y)\n",
    "        \n",
    "    training_B, edgeServer1_B, edgeServer2_B, edgeServer3_B, edgeServer4_B = runModel (model_b, model_train_X, model_train_Y,datasetType), runModel(model_b,edgeServer1_X, edgeServer1_Y,datasetType), runModel(model_b,edgeServer2_X, edgeServer2_Y,datasetType), runModel(model_b,edgeServer3_X, edgeServer3_Y,datasetType), runModel(model_b,edgeServer4_X, edgeServer4_Y,datasetType) \n",
    "    \n",
    "        \n",
    "    return training_B, edgeServer1_B, edgeServer2_B, edgeServer3_B, edgeServer4_B\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset for each case\n",
    "def Occupancy():\n",
    "    print(\"-------------- Occupancy Dataset Info -------------------- \")\n",
    "    df = pd.read_csv('C:/Users/moyin/Downloads/data/Occupancy.csv')\n",
    "    df.drop(columns = [\"date\"],inplace = True)\n",
    "    trainingAccuacy, edgeServer1Accuracy, edgeServer2Accuracy, edgeServer3Accuracy, edgeServer4Accuracy = loadData(df,'Occupancy',\"Categorical\")\n",
    "    training_A, edgeServer1_A, edgeServer2_A, edgeServer3_A, edgeServer4_A = loaddata (df,'Occupancy',\"Categorical\")\n",
    "    training_B, edgeServer1_B, edgeServer2_B, edgeServer3_B, edgeServer4_B = load_data (df,'Occupancy',\"Categorical\")\n",
    "    return \n",
    "\n",
    "\n",
    "def powerConsumption():\n",
    "    print(\"-------------- Power Consumption Dataset Info -------------------- \")\n",
    "    df = pd.read_csv('C:/Users/moyin/Downloads/data/Tetuan City power consumption.csv')\n",
    "    df.drop(columns = ['DateTime','Zone 2  Power Consumption', 'Zone 3  Power Consumption'],inplace = True)\n",
    "    trainingAccuacy, edgeServer1Accuracy, edgeServer2Accuracy, edgeServer3Accuracy, edgeServer4Accuracy = loadData(df,'Zone 1 Power Consumption',\"Continuous\")\n",
    "    training_A, edgeServer1_A, edgeServer2_A, edgeServer3_A, edgeServer4_A = loaddata (df,'Zone 1 Power Consumption',\"Continuous\")\n",
    "    training_B, edgeServer1_B, edgeServer2_B, edgeServer3_B, edgeServer4_B = load_data (df,'Zone 1 Power Consumption',\"Continuous\")\n",
    "    return \n",
    "\n",
    "def activity_wsdata():\n",
    "    print(\"-------------- Wearable Sensor Dataset Info -------------------- \")\n",
    "    df = pd.read_csv('C:/Users/moyin/Downloads/data/activity data.csv')\n",
    "    trainingAccuacy, edgeServer1Accuracy, edgeServer2Accuracy, edgeServer3Accuracy, edgeServer4Accuracy = loadData(df,'activity',\"Categorical\")\n",
    "    training_A, edgeServer1_A, edgeServer2_A, edgeServer3_A, edgeServer4_A = loaddata (df,'activity',\"Categorical\")\n",
    "    training_B, edgeServer1_B, edgeServer2_B, edgeServer3_B, edgeServer4_B = load_data (df,'activity',\"Categorical\")\n",
    "    return \n",
    "\n",
    "def ALEdata():\n",
    "    print(\"-------------- ALE Sensor Data Dataset Info -------------------- \")\n",
    "    df = pd.read_csv('C:/Users/moyin/Downloads/data/ALE in Sensor.csv')\n",
    "    trainingAccuacy, edgeServer1Accuracy, edgeServer2Accuracy, edgeServer3Accuracy, edgeServer4Accuracy = loadData(df,'sd_ale',\"Continuous\")\n",
    "    training_A, edgeServer1_A, edgeServer2_A, edgeServer3_A, edgeServer4_A  = loaddata (df,'sd_ale',\"Continuous\")\n",
    "    training_B, edgeServer1_B, edgeServer2_B, edgeServer3_B, edgeServer4_B = load_data (df,'sd_ale',\"Continuous\")\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"-------------- ALE Sensor Data Dataset Info -------------------- \")\n",
    "df = pd.read_csv('C:/Users/moyin/Downloads/data/ALE in Sensor.csv')\n",
    "trainingAccuacy, edgeServer1Accuracy, edgeServer2Accuracy, edgeServer3Accuracy, edgeServer4Accuracy = loadData(df,'sd_ale',\"Continuous\")\n",
    "training_A, edgeServer1_A, edgeServer2_A, edgeServer3_A, edgeServer4_A  = loaddata (df,'sd_ale',\"Continuous\")\n",
    "training_B, edgeServer1_B, edgeServer2_B, edgeServer3_B, edgeServer4_B = load_data (df,'sd_ale',\"Continuous\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Occupancy():\n",
    "    print(\"-------------- Occupancy Dataset Info -------------------- \")\n",
    "    df = pd.read_csv('C:/Users/moyin/Downloads/data/Occupancy.csv')\n",
    "    df.drop(columns = [\"date\"],inplace = True)\n",
    "    trainingAccuacy, edgeServer1Accuracy, edgeServer2Accuracy, edgeServer3Accuracy, edgeServer4Accuracy = loadData(df,'Occupancy',\"Categorical\")\n",
    "    training_A, edgeServer1_A, edgeServer2_A, edgeServer3_A, edgeServer4_A = loaddata (df,'Occupancy',\"Categorical\")\n",
    "    training_B, edgeServer1_B, edgeServer2_B, edgeServer3_B, edgeServer4_B = load_data (df,'Occupancy',\"Categorical\")\n",
    "    displayInfo(trainingAccuacy, edgeServer1Accuracy, edgeServer2Accuracy, edgeServer3Accuracy, edgeServer4Accuracy)\n",
    "    print(\"------------------------------------------------------------\")\n",
    "    displayInfo(training_A, edgeServer1_A, edgeServer2_A, edgeServer3_A, edgeServer4_A)\n",
    "    print(\"------------------------------------------------------------\")\n",
    "    displayInfo(training_B, edgeServer1_B, edgeServer2_B, edgeServer3_B, edgeServer4_B)\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def powerConsumption():\n",
    "    print(\"-------------- Power Consumption Dataset Info -------------------- \")\n",
    "    df = pd.read_csv('C:/Users/moyin/Downloads/data/Tetuan City power consumption.csv')\n",
    "    df.drop(columns = ['DateTime','Zone 2  Power Consumption', 'Zone 3  Power Consumption'],inplace = True)\n",
    "    trainingAccuacy, edgeServer1Accuracy, edgeServer2Accuracy, edgeServer3Accuracy, edgeServer4Accuracy = loadData(df,'Zone 1 Power Consumption',\"Continuous\")\n",
    "    training_A, edgeServer1_A, edgeServer2_A, edgeServer3_A, edgeServer4_A = loaddata (df,'Zone 1 Power Consumption',\"Continuous\")\n",
    "    training_B, edgeServer1_B, edgeServer2_B, edgeServer3_B, edgeServer4_B = load_data (df,'Zone 1 Power Consumption',\"Continuous\")\n",
    "    displayInfo(trainingAccuacy, edgeServer1Accuracy, edgeServer2Accuracy, edgeServer3Accuracy, edgeServer4Accuracy)\n",
    "    print(\"------------------------------------------------------------\")\n",
    "    displayInfo(training_A, edgeServer1_A, edgeServer2_A, edgeServer3_A, edgeServer4_A)\n",
    "    print(\"------------------------------------------------------------\")\n",
    "    displayInfo(training_B, edgeServer1_B, edgeServer2_B, edgeServer3_B, edgeServer4_B)\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accelerometer_w():\n",
    "    print(\"-------------- Accelerometer Dataset Info -------------------- \")\n",
    "    df = pd.read_csv('C:/Users/moyin/Downloads/data/accelerometer.csv')\n",
    "#     df.drop(columns = ['wconfid','pctid', 'x', 'y', 'z'],inplace = True)\n",
    "    trainingAccuacy, edgeServer1Accuracy, edgeServer2Accuracy, edgeServer3Accuracy, edgeServer4Accuracy = loadData(df,'wconfid',\"Continuous\")\n",
    "    training_A, edgeServer1_A, edgeServer2_A, edgeServer3_A, edgeServer4_A = loaddata (df,'wconfid',\"Continuous\")\n",
    "    training_B, edgeServer1_B, edgeServer2_B, edgeServer3_B, edgeServer4_B = load_data (df,'wconfid',\"Continuous\")\n",
    "    displayInfo(trainingAccuacy, edgeServer1Accuracy, edgeServer2Accuracy, edgeServer3Accuracy, edgeServer4Accuracy)\n",
    "    print(\"------------------------------------------------------------\")\n",
    "    displayInfo(training_A, edgeServer1_A, edgeServer2_A, edgeServer3_A, edgeServer4_A)\n",
    "    print(\"------------------------------------------------------------\")\n",
    "    displayInfo(training_B, edgeServer1_B, edgeServer2_B, edgeServer3_B, edgeServer4_B)\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activity_wsdata():\n",
    "    print(\"-------------- Wearable Sensor Dataset Info -------------------- \")\n",
    "    df = pd.read_csv('C:/Users/moyin/Downloads/data/activity data.csv')\n",
    "    trainingAccuacy, edgeServer1Accuracy, edgeServer2Accuracy, edgeServer3Accuracy, edgeServer4Accuracy = loadData(df,'activity',\"Categorical\")\n",
    "    training_A, edgeServer1_A, edgeServer2_A, edgeServer3_A, edgeServer4_A = loaddata (df,'activity',\"Categorical\")\n",
    "    training_B, edgeServer1_B, edgeServer2_B, edgeServer3_B, edgeServer4_B = load_data (df,'activity',\"Categorical\")\n",
    "    displayInfo(trainingAccuacy, edgeServer1Accuracy, edgeServer2Accuracy, edgeServer3Accuracy, edgeServer4Accuracy)\n",
    "    print(\"------------------------------------------------------------\")\n",
    "    displayInfo(training_A, edgeServer1_A, edgeServer2_A, edgeServer3_A, edgeServer4_A)\n",
    "    print(\"------------------------------------------------------------\")\n",
    "    displayInfo(training_B, edgeServer1_B, edgeServer2_B, edgeServer3_B, edgeServer4_B)\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ALEdata():\n",
    "    print(\"-------------- ALE Sensor Data Dataset Info -------------------- \")\n",
    "    df = pd.read_csv('C:/Users/moyin/Downloads/data/ALE in Sensor.csv')\n",
    "    trainingAccuacy, edgeServer1Accuracy, edgeServer2Accuracy, edgeServer3Accuracy, edgeServer4Accuracy = loadData(df,'sd_ale',\"Continuous\")\n",
    "    training_A, edgeServer1_A, edgeServer2_A, edgeServer3_A, edgeServer4_A  = loaddata (df,'sd_ale',\"Continuous\")\n",
    "    training_B, edgeServer1_B, edgeServer2_B, edgeServer3_B, edgeServer4_B = load_data (df,'sd_ale',\"Continuous\")\n",
    "    displayInfo(trainingAccuacy, edgeServer1Accuracy, edgeServer2Accuracy, edgeServer3Accuracy, edgeServer4Accuracy)\n",
    "    print(\"------------------------------------------------------------\")\n",
    "    displayInfo(training_A, edgeServer1_A, edgeServer2_A, edgeServer3_A, edgeServer4_A)\n",
    "    print(\"------------------------------------------------------------\")\n",
    "    displayInfo(training_B, edgeServer1_B, edgeServer2_B, edgeServer3_B, edgeServer4_B)\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def banknote_data():\n",
    "    print(\"-------------- Bank Note Authentication Dataset Info -------------------- \")\n",
    "    df = pd.read_csv('C:/Users/moyin/Downloads/data/banknote_authen.txt')\n",
    "    trainingAccuacy, edgeServer1Accuracy, edgeServer2Accuracy, edgeServer3Accuracy, edgeServer4Accuracy = loadData(df,'class',\"Categorical\")\n",
    "    training_A, edgeServer1_A, edgeServer2_A, edgeServer3_A, edgeServer4_A = loaddata (df,'class',\"Categorical\")\n",
    "    training_B, edgeServer1_B, edgeServer2_B, edgeServer3_B, edgeServer4_B = load_data (df,'class',\"Categorical\")\n",
    "    displayInfo(trainingAccuacy, edgeServer1Accuracy, edgeServer2Accuracy, edgeServer3Accuracy, edgeServer4Accuracy)\n",
    "    print(\"------------------------------------------------------------\")\n",
    "    displayInfo(training_A, edgeServer1_A, edgeServer2_A, edgeServer3_A, edgeServer4_A)\n",
    "    print(\"------------------------------------------------------------\")\n",
    "    displayInfo(training_B, edgeServer1_B, edgeServer2_B, edgeServer3_B, edgeServer4_B)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RSSI():\n",
    "    print(\"-------------- BLE RSSI Dataset Info -------------------- \")\n",
    "    df = pd.read_csv('C:/Users/moyin/Downloads/data/BLE RSSI.csv')\n",
    "    df.drop(columns = ['name'],inplace = True)\n",
    "    trainingAccuacy, edgeServer1Accuracy, edgeServer2Accuracy, edgeServer3Accuracy, edgeServer4Accuracy = loadData(df,'locationStatus', \"Categorical\")\n",
    "    training_A, edgeServer1_A, edgeServer2_A, edgeServer3_A, edgeServer4_A  = loaddata (df,'locationStatus', \"Categorical\")\n",
    "    training_B, edgeServer1_B, edgeServer2_B, edgeServer3_B, edgeServer4_B  = load_data (df,'locationStatus', \"Categorical\")\n",
    "    displayInfo(trainingAccuacy, edgeServer1Accuracy, edgeServer2Accuracy, edgeServer3Accuracy, edgeServer4Accuracy)\n",
    "    print(\"------------------------------------------------------------\")\n",
    "    displayInfo(training_A, edgeServer1_A, edgeServer2_A, edgeServer3_A, edgeServer4_A)\n",
    "    print(\"------------------------------------------------------------\")\n",
    "    displayInfo(training_B, edgeServer1_B, edgeServer2_B, edgeServer3_B, edgeServer4_B)\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def e_grid():\n",
    "    print(\"-------------- Simulated Electrical Grid Dataset Info -------------------- \")\n",
    "    df = pd.read_csv('C:/Users/moyin/Downloads/data/UCI_named.csv')\n",
    "    trainingAccuacy, edgeServer1Accuracy, edgeServer2Accuracy, edgeServer3Accuracy, edgeServer4Accuracy = loadData(df,'stabf', 'Categorical')\n",
    "    training_A, edgeServer1_A, edgeServer2_A, edgeServer3_A, edgeServer4_A  = loaddata (df,'stabf', 'Categorical')\n",
    "    training_B, edgeServer1_B, edgeServer2_B, edgeServer3_B, edgeServer4_B = load_data (df,'stabf', 'Categorical')\n",
    "    displayInfo(trainingAccuacy, edgeServer1Accuracy, edgeServer2Accuracy, edgeServer3Accuracy, edgeServer4Accuracy)\n",
    "    print(\"------------------------------------------------------------\")\n",
    "    displayInfo(training_A, edgeServer1_A, edgeServer2_A, edgeServer3_A, edgeServer4_A)\n",
    "    print(\"------------------------------------------------------------\")\n",
    "    displayInfo(training_B, edgeServer1_B, edgeServer2_B, edgeServer3_B, edgeServer4_B)\n",
    "    return  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__==\"__main__\":\n",
    "#     Occupancy()\n",
    "#     powerConsumption()\n",
    "#     accelerometer_w()\n",
    "#     activity_wsdata()\n",
    "#     ALEdata()\n",
    "#     banknote_data()\n",
    "#     RSSI()\n",
    "#     e_grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Occupancy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "powerConsumption()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accelerometer_w()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_wsdata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALEdata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "banknote_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RSSI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData (df,predictName: str,datasetType: str):\n",
    "\n",
    "    X = df.drop(columns=[predictName])  \n",
    "    y = df[predictName]                \n",
    "    \n",
    "    # First split: Split data into two halves (50% training and 50% for further splits)\n",
    "    model_train_X, X_remaining, model_train_Y, y_remaining = train_test_split(X, y, train_size=0.5, random_state=42)\n",
    "    \n",
    "    # Second split: Split the remaining data into 2 (50% for edge server 1 and 50% for edge server 2)\n",
    "    edgeServer1_X, edgeServer2_X, edgeServer1_Y, edgeServer2_Y = train_test_split(X_remaining, y_remaining, train_size=0.5, random_state=42)\n",
    "    \n",
    "    # Third split: Split the remaining data into 2 (50% for edge server 3 and 50% for edge server 4)\n",
    "    edgeServer3_X, edgeServer4_X, edgeServer3_Y, edgeServer4_Y = train_test_split(X_remaining, y_remaining, train_size=0.5, random_state=42)\n",
    "    \n",
    "    if datasetType == \"Categorical\":\n",
    "        model = trainCategoricalModel (model_train_X, model_train_Y)\n",
    "        \n",
    "    else:\n",
    "        model = trainContinuousModel (model_train_X, model_train_Y)\n",
    "        \n",
    "        \n",
    "    trainingAccuacy, edgeServer1Accuracy, edgeServer2Accuracy, edgeServer3Accuracy, edgeServer4Accuracy = runModel (model, model_train_X, model_train_Y,datasetType), runModel(model,edgeServer1_X, edgeServer1_Y,datasetType), runModel(model,edgeServer2_X, edgeServer2_Y,datasetType), runModel(model,edgeServer3_X, edgeServer3_Y,datasetType), runModel(model,edgeServer4_X, edgeServer4_Y,datasetType)\n",
    "\n",
    "    return trainingAccuacy, edgeServer1Accuracy, edgeServer2Accuracy, edgeServer3Accuracy, edgeServer4Accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"-------------- Occupancy Dataset Info -------------------- \")\n",
    "\n",
    "df = pd.read_csv('C:/Users/moyin/Downloads/data/Occupancy.csv')\n",
    "df.drop(columns = [\"date\"],inplace = True)\n",
    "trainingAccuacy, edgeServer1Accuracy, edgeServer2Accuracy, edgeServer3Accuracy, edgeServer4Accuracy = loadData(df,'Occupancy',\"Categorical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "training_A, edgeServer1_A, edgeServer2_A, edgeServer3_A, edgeServer4_A  = loaddata (df,'locationStatus', \"Categorical\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
