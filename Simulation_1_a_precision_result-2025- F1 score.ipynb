{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install fast_ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression,LinearRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics, svm\n",
    "from fast_ml.model_development import train_valid_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def fModel(Y_predicted, Y_true, datasetType: str, model):\n",
    "    if datasetType == \"Categorical\":\n",
    "        return metrics.f1_score(Y_predicted, Y_true, average = 'macro')\n",
    "    return metrics.mean_squared_error(Y_true, Y_predicted)\n",
    "\n",
    "\n",
    "def runModel(model, X_test, Y_test, datasetType: str): \n",
    "    Y_predicted = model.predict(X_test)\n",
    "    return fModel(Y_predicted, Y_test,datasetType, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models\n",
    "def trainCategoricalModel (X,Y):\n",
    "    return LogisticRegression().fit(X, Y)\n",
    "\n",
    "def trainCatergoricalModel_ (X,Y):\n",
    "    return GaussianNB().fit(X, Y)\n",
    "\n",
    "def trainCatModel (X,Y):\n",
    "    model  = svm.SVC(kernel='linear')\n",
    "    return model.fit(X, Y)\n",
    "\n",
    "def trainContinuousModel (X,Y):\n",
    "    return LinearRegression().fit(X, Y)\n",
    "\n",
    "def trainContinuousModel_ (X,Y):\n",
    "    Y = Y.astype('int')\n",
    "    model = KNeighborsClassifier(n_neighbors=1)\n",
    "    return model.fit(X,Y)\n",
    "\n",
    "def trainConModel(X,Y):\n",
    "    Y = Y.astype('int')\n",
    "    model = RandomForestRegressor(n_estimators= 1000, random_state=42)\n",
    "    return model.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def displayInfo (training, edge1, edge2, edge3, edge4):\n",
    "    print (\"F1 Score on Training Data: \", training)\n",
    "    print (\"F1 Score on edge1 Data: \", edge1)\n",
    "    print (\"F1 Score on edge2 Data: \", edge2)\n",
    "    print (\"F1 Score on edge3 Data: \", edge3)\n",
    "    print (\"F1 Score on edge4 Data: \", edge4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData (df,predictName: str,datasetType: str):\n",
    "\n",
    "    X = df.drop(columns=[predictName])  # Features\n",
    "    y = df[predictName]                # Target\n",
    "    \n",
    "    # First split: Split data into two halves (50% training and 50% for further splits)\n",
    "    model_train_X, X_remaining, model_train_Y, y_remaining = train_test_split(X, y, train_size=0.4, random_state=42)\n",
    "    \n",
    "    # Second split: Split the remaining data into 2 (50% for edge server 1 and 50% for edge server 2)\n",
    "    edgeServer1_X, edgeServer2_X, edgeServer1_Y, edgeServer2_Y = train_test_split(X_remaining, y_remaining, train_size=0.5, random_state=42)\n",
    "    \n",
    "    # Third split: Split the remaining data into 2 (50% for edge server 3 and 50% for edge server 4)\n",
    "    edgeServer3_X, edgeServer4_X, edgeServer3_Y, edgeServer4_Y = train_test_split(X_remaining, y_remaining, train_size=0.5, random_state=42)\n",
    "    \n",
    "    if datasetType == \"Categorical\":\n",
    "        model = trainCategoricalModel (model_train_X, model_train_Y)\n",
    "        \n",
    "    else:\n",
    "        model = trainContinuousModel (model_train_X, model_train_Y)\n",
    "        \n",
    "        \n",
    "    trainingAccuacy, edgeServer1Accuracy, edgeServer2Accuracy, edgeServer3Accuracy, edgeServer4Accuracy = runModel (model, model_train_X, model_train_Y,datasetType), runModel(model,edgeServer1_X, edgeServer1_Y,datasetType), runModel(model,edgeServer2_X, edgeServer2_Y,datasetType), runModel(model,edgeServer3_X, edgeServer3_Y,datasetType), runModel(model,edgeServer4_X, edgeServer4_Y,datasetType)\n",
    "\n",
    "    return trainingAccuacy, edgeServer1Accuracy, edgeServer2Accuracy, edgeServer3Accuracy, edgeServer4Accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loaddata (df,predictName: str,datasetType: str):\n",
    "    \n",
    "    X = df.drop(columns=[predictName])  # Features\n",
    "    y = df[predictName]                # Target\n",
    "    \n",
    "    # First split: Split data into two halves (50% training and 50% for further splits)\n",
    "    model_train_X, X_remaining, model_train_Y, y_remaining = train_test_split(X, y, train_size=0.4, random_state=42)\n",
    "    \n",
    "    # Second split: Split the remaining data into 2 (50% for edge server 1 and 50% for edge server 2)\n",
    "    edgeServer1_X, edgeServer2_X, edgeServer1_Y, edgeServer2_Y = train_test_split(X_remaining, y_remaining, train_size=0.5, random_state=42)\n",
    "    \n",
    "    # Third split: Split the remaining data into 2 (50% for edge server 3 and 50% for edge server 4)\n",
    "    edgeServer3_X, edgeServer4_X, edgeServer3_Y, edgeServer4_Y = train_test_split(X_remaining, y_remaining, train_size=0.5, random_state=42)\n",
    "    \n",
    "    if datasetType == \"Categorical\":\n",
    "        \n",
    "        model_a = trainCatergoricalModel_(model_train_X, model_train_Y)\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        model_a = trainContinuousModel_(model_train_X, model_train_Y)   \n",
    "    \n",
    "\n",
    "    training_A, edgeServer1_A, edgeServer2_A, edgeServer3_A, edgeServer4_A = runModel (model_a, model_train_X, model_train_Y,datasetType), runModel(model_a,edgeServer1_X, edgeServer1_Y,datasetType), runModel(model_a,edgeServer2_X, edgeServer2_Y,datasetType), runModel(model_a,edgeServer3_X, edgeServer3_Y,datasetType), runModel(model_a,edgeServer4_X, edgeServer4_Y,datasetType)\n",
    "    \n",
    "    return training_A, edgeServer1_A, edgeServer2_A, edgeServer3_A, edgeServer4_A\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data (df,predictName: str,datasetType: str):\n",
    "    \n",
    "    X = df.drop(columns=[predictName])  # Features\n",
    "    y = df[predictName]                # Target\n",
    "    \n",
    "    # First split: Split data into two halves (50% training and 50% for further splits)\n",
    "    model_train_X, X_remaining, model_train_Y, y_remaining = train_test_split(X, y, train_size=0.4, random_state=42)\n",
    "    \n",
    "    # Second split: Split the remaining data into 2 (50% for edge server 1 and 50% for edge server 2)\n",
    "    edgeServer1_X, edgeServer2_X, edgeServer1_Y, edgeServer2_Y = train_test_split(X_remaining, y_remaining, train_size=0.5, random_state=42)\n",
    "    \n",
    "    # Third split: Split the remaining data into 2 (50% for edge server 3 and 50% for edge server 4)\n",
    "    edgeServer3_X, edgeServer4_X, edgeServer3_Y, edgeServer4_Y = train_test_split(X_remaining, y_remaining, train_size=0.5, random_state=42)\n",
    "\n",
    "    \n",
    "    if datasetType == \"Categorical\":\n",
    "        \n",
    "        model_b = trainCatModel(model_train_X, model_train_Y)\n",
    "        \n",
    "    else:\n",
    "       \n",
    "        model_b = trainConModel(model_train_X, model_train_Y)\n",
    "        \n",
    "    training_B, edgeServer1_B, edgeServer2_B, edgeServer3_B, edgeServer4_B = runModel (model_b, model_train_X, model_train_Y,datasetType), runModel(model_b,edgeServer1_X, edgeServer1_Y,datasetType), runModel(model_b,edgeServer2_X, edgeServer2_Y,datasetType), runModel(model_b,edgeServer3_X, edgeServer3_Y,datasetType), runModel(model_b,edgeServer4_X, edgeServer4_Y,datasetType) \n",
    "    \n",
    "        \n",
    "    return training_B, edgeServer1_B, edgeServer2_B, edgeServer3_B, edgeServer4_B\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Occupancy():\n",
    "    print(\"-------------- Occupancy Dataset Info -------------------- \")\n",
    "    df = pd.read_csv('C:/Users/moyin/Downloads/data/Occupancy.csv')\n",
    "    df.drop(columns = [\"date\"],inplace = True)\n",
    "    trainingAccuacy, edgeServer1Accuracy, edgeServer2Accuracy, edgeServer3Accuracy, edgeServer4Accuracy = loadData(df,'Occupancy',\"Categorical\")\n",
    "    training_A, edgeServer1_A, edgeServer2_A, edgeServer3_A, edgeServer4_A = loaddata (df,'Occupancy',\"Categorical\")\n",
    "    training_B, edgeServer1_B, edgeServer2_B, edgeServer3_B, edgeServer4_B = load_data (df,'Occupancy',\"Categorical\")\n",
    "    displayInfo(trainingAccuacy, edgeServer1Accuracy, edgeServer2Accuracy, edgeServer3Accuracy, edgeServer4Accuracy)\n",
    "    print(\"------------------------------------------------------------\")\n",
    "    displayInfo(training_A, edgeServer1_A, edgeServer2_A, edgeServer3_A, edgeServer4_A)\n",
    "    print(\"------------------------------------------------------------\")\n",
    "    displayInfo(training_B, edgeServer1_B, edgeServer2_B, edgeServer3_B, edgeServer4_B)\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def powerConsumption():\n",
    "    print(\"-------------- Power Consumption Dataset Info -------------------- \")\n",
    "    df = pd.read_csv('C:/Users/moyin/Downloads/data/Tetuan City power consumption.csv')\n",
    "    df.drop(columns = ['DateTime','Zone 2  Power Consumption', 'Zone 3  Power Consumption'],inplace = True)\n",
    "    trainingAccuacy, edgeServer1Accuracy, edgeServer2Accuracy, edgeServer3Accuracy, edgeServer4Accuracy = loadData(df,'Zone 1 Power Consumption',\"Continuous\")\n",
    "    training_A, edgeServer1_A, edgeServer2_A, edgeServer3_A, edgeServer4_A = loaddata (df,'Zone 1 Power Consumption',\"Continuous\")\n",
    "    training_B, edgeServer1_B, edgeServer2_B, edgeServer3_B, edgeServer4_B = load_data (df,'Zone 1 Power Consumption',\"Continuous\")\n",
    "    displayInfo(trainingAccuacy, edgeServer1Accuracy, edgeServer2Accuracy, edgeServer3Accuracy, edgeServer4Accuracy)\n",
    "    print(\"------------------------------------------------------------\")\n",
    "    displayInfo(training_A, edgeServer1_A, edgeServer2_A, edgeServer3_A, edgeServer4_A)\n",
    "    print(\"------------------------------------------------------------\")\n",
    "    displayInfo(training_B, edgeServer1_B, edgeServer2_B, edgeServer3_B, edgeServer4_B)\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accelerometer_w():\n",
    "    print(\"-------------- Accelerometer Dataset Info -------------------- \")\n",
    "    df = pd.read_csv('C:/Users/moyin/Downloads/data/accelerometer.csv')\n",
    "#     df.drop(columns = ['wconfid','pctid', 'x', 'y', 'z'],inplace = True)\n",
    "    trainingAccuacy, edgeServer1Accuracy, edgeServer2Accuracy, edgeServer3Accuracy, edgeServer4Accuracy = loadData(df,'wconfid',\"Continuous\")\n",
    "    training_A, edgeServer1_A, edgeServer2_A, edgeServer3_A, edgeServer4_A = loaddata (df,'wconfid',\"Continuous\")\n",
    "    training_B, edgeServer1_B, edgeServer2_B, edgeServer3_B, edgeServer4_B = load_data (df,'wconfid',\"Continuous\")\n",
    "    displayInfo(trainingAccuacy, edgeServer1Accuracy, edgeServer2Accuracy, edgeServer3Accuracy, edgeServer4Accuracy)\n",
    "    print(\"------------------------------------------------------------\")\n",
    "    displayInfo(training_A, edgeServer1_A, edgeServer2_A, edgeServer3_A, edgeServer4_A)\n",
    "    print(\"------------------------------------------------------------\")\n",
    "    displayInfo(training_B, edgeServer1_B, edgeServer2_B, edgeServer3_B, edgeServer4_B)\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activity_wsdata():\n",
    "    print(\"-------------- Wearable Sensor Dataset Info -------------------- \")\n",
    "    df = pd.read_csv('C:/Users/moyin/Downloads/data/activity data.csv')\n",
    "    trainingAccuacy, edgeServer1Accuracy, edgeServer2Accuracy, edgeServer3Accuracy, edgeServer4Accuracy = loadData(df,'activity',\"Categorical\")\n",
    "    training_A, edgeServer1_A, edgeServer2_A, edgeServer3_A, edgeServer4_A = loaddata (df,'activity',\"Categorical\")\n",
    "    training_B, edgeServer1_B, edgeServer2_B, edgeServer3_B, edgeServer4_B = load_data (df,'activity',\"Categorical\")\n",
    "    displayInfo(trainingAccuacy, edgeServer1Accuracy, edgeServer2Accuracy, edgeServer3Accuracy, edgeServer4Accuracy)\n",
    "    print(\"------------------------------------------------------------\")\n",
    "    displayInfo(training_A, edgeServer1_A, edgeServer2_A, edgeServer3_A, edgeServer4_A)\n",
    "    print(\"------------------------------------------------------------\")\n",
    "    displayInfo(training_B, edgeServer1_B, edgeServer2_B, edgeServer3_B, edgeServer4_B)\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ALEdata():\n",
    "    print(\"-------------- ALE Sensor Data Dataset Info -------------------- \")\n",
    "    df = pd.read_csv('C:/Users/moyin/Downloads/data/ALE in Sensor.csv')\n",
    "    trainingAccuacy, edgeServer1Accuracy, edgeServer2Accuracy, edgeServer3Accuracy, edgeServer4Accuracy = loadData(df,'sd_ale',\"Continuous\")\n",
    "    training_A, edgeServer1_A, edgeServer2_A, edgeServer3_A, edgeServer4_A  = loaddata (df,'sd_ale',\"Continuous\")\n",
    "    training_B, edgeServer1_B, edgeServer2_B, edgeServer3_B, edgeServer4_B = load_data (df,'sd_ale',\"Continuous\")\n",
    "    displayInfo(trainingAccuacy, edgeServer1Accuracy, edgeServer2Accuracy, edgeServer3Accuracy, edgeServer4Accuracy)\n",
    "    print(\"------------------------------------------------------------\")\n",
    "    displayInfo(training_A, edgeServer1_A, edgeServer2_A, edgeServer3_A, edgeServer4_A)\n",
    "    print(\"------------------------------------------------------------\")\n",
    "    displayInfo(training_B, edgeServer1_B, edgeServer2_B, edgeServer3_B, edgeServer4_B)\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def banknote_data():\n",
    "    print(\"-------------- Bank Note Authentication Dataset Info -------------------- \")\n",
    "    df = pd.read_csv('C:/Users/moyin/Downloads/data/banknote_authen.txt')\n",
    "    trainingAccuacy, edgeServer1Accuracy, edgeServer2Accuracy, edgeServer3Accuracy, edgeServer4Accuracy = loadData(df,'class',\"Categorical\")\n",
    "    training_A, edgeServer1_A, edgeServer2_A, edgeServer3_A, edgeServer4_A = loaddata (df,'class',\"Categorical\")\n",
    "    training_B, edgeServer1_B, edgeServer2_B, edgeServer3_B, edgeServer4_B = load_data (df,'class',\"Categorical\")\n",
    "    displayInfo(trainingAccuacy, edgeServer1Accuracy, edgeServer2Accuracy, edgeServer3Accuracy, edgeServer4Accuracy)\n",
    "    print(\"------------------------------------------------------------\")\n",
    "    displayInfo(training_A, edgeServer1_A, edgeServer2_A, edgeServer3_A, edgeServer4_A)\n",
    "    print(\"------------------------------------------------------------\")\n",
    "    displayInfo(training_B, edgeServer1_B, edgeServer2_B, edgeServer3_B, edgeServer4_B)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RSSI():\n",
    "    print(\"-------------- BLE RSSI Dataset Info -------------------- \")\n",
    "    df = pd.read_csv('C:/Users/moyin/Downloads/data/BLE RSSI.csv')\n",
    "    df.drop(columns = ['name'],inplace = True)\n",
    "    trainingAccuacy, edgeServer1Accuracy, edgeServer2Accuracy, edgeServer3Accuracy, edgeServer4Accuracy = loadData(df,'locationStatus', \"Categorical\")\n",
    "    training_A, edgeServer1_A, edgeServer2_A, edgeServer3_A, edgeServer4_A  = loaddata (df,'locationStatus', \"Categorical\")\n",
    "    training_B, edgeServer1_B, edgeServer2_B, edgeServer3_B, edgeServer4_B  = load_data (df,'locationStatus', \"Categorical\")\n",
    "    displayInfo(trainingAccuacy, edgeServer1Accuracy, edgeServer2Accuracy, edgeServer3Accuracy, edgeServer4Accuracy)\n",
    "    print(\"------------------------------------------------------------\")\n",
    "    displayInfo(training_A, edgeServer1_A, edgeServer2_A, edgeServer3_A, edgeServer4_A)\n",
    "    print(\"------------------------------------------------------------\")\n",
    "    displayInfo(training_B, edgeServer1_B, edgeServer2_B, edgeServer3_B, edgeServer4_B)\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def e_grid():\n",
    "    print(\"-------------- Simulated Electrical Grid Dataset Info -------------------- \")\n",
    "    df = pd.read_csv('C:/Users/moyin/Downloads/data/UCI_named.csv')\n",
    "    trainingAccuacy, edgeServer1Accuracy, edgeServer2Accuracy, edgeServer3Accuracy, edgeServer4Accuracy = loadData(df,'stabf', 'Categorical')\n",
    "    training_A, edgeServer1_A, edgeServer2_A, edgeServer3_A, edgeServer4_A  = loaddata (df,'stabf', 'Categorical')\n",
    "    training_B, edgeServer1_B, edgeServer2_B, edgeServer3_B, edgeServer4_B = load_data (df,'stabf', 'Categorical')\n",
    "    displayInfo(trainingAccuacy, edgeServer1Accuracy, edgeServer2Accuracy, edgeServer3Accuracy, edgeServer4Accuracy)\n",
    "    print(\"------------------------------------------------------------\")\n",
    "    displayInfo(training_A, edgeServer1_A, edgeServer2_A, edgeServer3_A, edgeServer4_A)\n",
    "    print(\"------------------------------------------------------------\")\n",
    "    displayInfo(training_B, edgeServer1_B, edgeServer2_B, edgeServer3_B, edgeServer4_B)\n",
    "    return  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__==\"__main__\":\n",
    "#     Occupancy()\n",
    "#     powerConsumption()\n",
    "#     accelerometer_w()\n",
    "#     activity_wsdata()\n",
    "#     ALEdata()\n",
    "#     banknote_data()\n",
    "#     RSSI()\n",
    "#     e_grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------- Occupancy Dataset Info -------------------- \n",
      "F1 Score on Training Data:  0.9819942364636209\n",
      "F1 Score on edge1 Data:  0.9869577676135979\n",
      "F1 Score on edge2 Data:  0.9861240265635398\n",
      "F1 Score on edge3 Data:  0.9869577676135979\n",
      "F1 Score on edge4 Data:  0.9861240265635398\n",
      "------------------------------------------------------------\n",
      "F1 Score on Training Data:  0.9548665056633183\n",
      "F1 Score on edge1 Data:  0.9593022109065386\n",
      "F1 Score on edge2 Data:  0.9550172947293115\n",
      "F1 Score on edge3 Data:  0.9593022109065386\n",
      "F1 Score on edge4 Data:  0.9550172947293115\n",
      "------------------------------------------------------------\n",
      "F1 Score on Training Data:  0.9820007543733461\n",
      "F1 Score on edge1 Data:  0.9871856773037787\n",
      "F1 Score on edge2 Data:  0.9859101485155426\n",
      "F1 Score on edge3 Data:  0.9871856773037787\n",
      "F1 Score on edge4 Data:  0.9859101485155426\n"
     ]
    }
   ],
   "source": [
    "Occupancy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------- Power Consumption Dataset Info -------------------- \n",
      "F1 Score on Training Data:  40321075.89790141\n",
      "F1 Score on edge1 Data:  40287870.72399557\n",
      "F1 Score on edge2 Data:  40352702.26927748\n",
      "F1 Score on edge3 Data:  40287870.72399557\n",
      "F1 Score on edge4 Data:  40352702.26927748\n",
      "------------------------------------------------------------\n",
      "F1 Score on Training Data:  0.32424237774569675\n",
      "F1 Score on edge1 Data:  53362707.11958031\n",
      "F1 Score on edge2 Data:  53785263.2968509\n",
      "F1 Score on edge3 Data:  53362707.11958031\n",
      "F1 Score on edge4 Data:  53785263.2968509\n",
      "------------------------------------------------------------\n",
      "F1 Score on Training Data:  3313505.068222254\n",
      "F1 Score on edge1 Data:  25036722.767848965\n",
      "F1 Score on edge2 Data:  24870460.55589165\n",
      "F1 Score on edge3 Data:  25036722.767848965\n",
      "F1 Score on edge4 Data:  24870460.55589165\n"
     ]
    }
   ],
   "source": [
    "powerConsumption()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------- Accelerometer Dataset Info -------------------- \n",
      "F1 Score on Training Data:  0.6665273789536503\n",
      "F1 Score on edge1 Data:  0.6679144626099887\n",
      "F1 Score on edge2 Data:  0.6655025745497011\n",
      "F1 Score on edge3 Data:  0.6679144626099887\n",
      "F1 Score on edge4 Data:  0.6655025745497011\n",
      "------------------------------------------------------------\n",
      "F1 Score on Training Data:  0.031209150326797386\n",
      "F1 Score on edge1 Data:  0.5\n",
      "F1 Score on edge2 Data:  0.4989760348583878\n",
      "F1 Score on edge3 Data:  0.5\n",
      "F1 Score on edge4 Data:  0.4989760348583878\n",
      "------------------------------------------------------------\n",
      "F1 Score on Training Data:  0.05148081948244786\n",
      "F1 Score on edge1 Data:  0.30055413311908563\n",
      "F1 Score on edge2 Data:  0.2960915114527583\n",
      "F1 Score on edge3 Data:  0.30055413311908563\n",
      "F1 Score on edge4 Data:  0.2960915114527583\n"
     ]
    }
   ],
   "source": [
    "accelerometer_w()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------- Wearable Sensor Dataset Info -------------------- \n",
      "F1 Score on Training Data:  0.748989898989899\n",
      "F1 Score on edge1 Data:  0.5542060278902384\n",
      "F1 Score on edge2 Data:  0.3306379155435759\n",
      "F1 Score on edge3 Data:  0.5542060278902384\n",
      "F1 Score on edge4 Data:  0.3306379155435759\n",
      "------------------------------------------------------------\n",
      "F1 Score on Training Data:  1.0\n",
      "F1 Score on edge1 Data:  0.6657657657657657\n",
      "F1 Score on edge2 Data:  0.3310841205578048\n",
      "F1 Score on edge3 Data:  0.6657657657657657\n",
      "F1 Score on edge4 Data:  0.3310841205578048\n",
      "------------------------------------------------------------\n",
      "F1 Score on Training Data:  1.0\n",
      "F1 Score on edge1 Data:  0.5555555555555555\n",
      "F1 Score on edge2 Data:  0.42766808620467156\n",
      "F1 Score on edge3 Data:  0.5555555555555555\n",
      "F1 Score on edge4 Data:  0.42766808620467156\n"
     ]
    }
   ],
   "source": [
    "activity_wsdata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------- ALE Sensor Data Dataset Info -------------------- \n",
      "F1 Score on Training Data:  0.009856677104670638\n",
      "F1 Score on edge1 Data:  0.013456816495941125\n",
      "F1 Score on edge2 Data:  0.014464094915140807\n",
      "F1 Score on edge3 Data:  0.013456816495941125\n",
      "F1 Score on edge4 Data:  0.014464094915140807\n",
      "------------------------------------------------------------\n",
      "F1 Score on Training Data:  0.10007447064704568\n",
      "F1 Score on edge1 Data:  0.12150006146673337\n",
      "F1 Score on edge2 Data:  0.09173887210476422\n",
      "F1 Score on edge3 Data:  0.12150006146673337\n",
      "F1 Score on edge4 Data:  0.09173887210476422\n",
      "------------------------------------------------------------\n",
      "F1 Score on Training Data:  0.10007447064704568\n",
      "F1 Score on edge1 Data:  0.12150006146673337\n",
      "F1 Score on edge2 Data:  0.09173887210476422\n",
      "F1 Score on edge3 Data:  0.12150006146673337\n",
      "F1 Score on edge4 Data:  0.09173887210476422\n"
     ]
    }
   ],
   "source": [
    "ALEdata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------- Bank Note Authentication Dataset Info -------------------- \n",
      "F1 Score on Training Data:  0.9908294648624587\n",
      "F1 Score on edge1 Data:  0.9925959205678857\n",
      "F1 Score on edge2 Data:  0.9876598676131428\n",
      "F1 Score on edge3 Data:  0.9925959205678857\n",
      "F1 Score on edge4 Data:  0.9876598676131428\n",
      "------------------------------------------------------------\n",
      "F1 Score on Training Data:  0.8469989471170181\n",
      "F1 Score on edge1 Data:  0.8474101868211266\n",
      "F1 Score on edge2 Data:  0.8091938675471994\n",
      "F1 Score on edge3 Data:  0.8474101868211266\n",
      "F1 Score on edge4 Data:  0.8091938675471994\n",
      "------------------------------------------------------------\n",
      "F1 Score on Training Data:  0.9926654620892725\n",
      "F1 Score on edge1 Data:  0.9925959205678857\n",
      "F1 Score on edge2 Data:  0.9876598676131428\n",
      "F1 Score on edge3 Data:  0.9925959205678857\n",
      "F1 Score on edge4 Data:  0.9876598676131428\n"
     ]
    }
   ],
   "source": [
    "banknote_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------- BLE RSSI Dataset Info -------------------- \n"
     ]
    }
   ],
   "source": [
    "RSSI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
